{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the StrokeMRI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into pandas dataframe\n",
    "\n",
    "How do we define which files should be stitched together?\n",
    "options:\n",
    "- all files in folder\n",
    "- based on suffix (e.g. \"n=895_06-Feb-2023_PVC2.tsv\")\n",
    "- check first columns to see whether it matches\n",
    "\n",
    "For now, we will will use the first option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_folder= 'StrokeMRI_correct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "root_directory = config.get_directory('raw_data')\n",
    "if os.path.isdir(os.path.join(root_directory, experiment_folder)):\n",
    "    print(\"this folder exists, we will take tsv from here\")\n",
    "else: \n",
    "    print(\"this folder does not seem to exist, try typing again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = config.get_directory('raw_data')\n",
    "tsv_path = os.path.join(root_directory, experiment_folder)\n",
    "\n",
    "tsv_files = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('.tsv')]\n",
    "tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files into dataframes\n",
    "dataframes = [pd.read_csv(file, sep='\\t', header=[0,1], index_col=0) for file in tsv_files]\n",
    "sample_df = dataframes[0]\n",
    "cols = sample_df.columns\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy identical columns from any file\n",
    "\n",
    "we could also read it from the data, but if it's always the same, we can just define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new method\n",
    "## will be recoded with function call from main branch\n",
    "\n",
    "def check_identical_columns(tsv_path):\n",
    "    \"\"\"\n",
    "    Here we enter the path to a folder, then return which columns which in\n",
    "    all files are exactly duplicated.In name and values\n",
    "    \"\"\"\n",
    "    tsv_files = glob.glob(os.path.join(tsv_path, '*.tsv'))\n",
    "    dataframes = [\n",
    "        pd.read_csv(file, sep='\\t', header=[0, 1], index_col=0)\n",
    "        for file in tsv_files\n",
    "    ]\n",
    "    key_df, *rest_dfs = dataframes\n",
    "\n",
    "    shared_columns = set(key_df.columns)\n",
    "\n",
    "    for frame in rest_dfs:\n",
    "        # check which labels are shared\n",
    "        shared_columns = shared_columns.intersection(frame.columns)\n",
    "\n",
    "    result = []\n",
    "    for column in shared_columns:\n",
    "        for frame in rest_dfs:\n",
    "            if not frame[column].equals(key_df[column]):\n",
    "                break\n",
    "        else:\n",
    "            result.append(column)\n",
    "    return result\n",
    "\n",
    "identical_columns = check_identical_columns(tsv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched = sample_df[identical_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_identical = stitched.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stitched = sample_df[cols[:n_identical]].copy()\n",
    "stitched['renumber'] = stitched.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add unique columns from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in dataframes:\n",
    "    for col in df.columns[n_identical:]:\n",
    "        stitched[col] = df[col]\n",
    "\n",
    "stitched.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sex and age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexage_path = os.path.join(root_directory, 'age_data', 'Age_Sex_StrokeMRI.csv')\n",
    "sexage_df = pd.read_csv(sexage_path, index_col=0)\n",
    "sexage_df['renumber'] = sexage_df.index\n",
    "sexage_df['renumber'] = sexage_df['renumber'].apply(str)\n",
    "\n",
    "#sexage_df['renumber']\n",
    "# tp 2 then + '2_1' if 1 then 1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be recoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df.loc[sexage_df.TP == 1, 'add_column'] = \"_1\"\n",
    "sexage_df.loc[sexage_df.TP == 2, 'add_column'] = \"_2\"\n",
    "sexage_df['renumber'] = sexage_df['renumber'] + sexage_df['add_column']\n",
    "\n",
    "sexage_df['renumber'] = 'sub-'+ sexage_df['renumber'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we need to reformat the participant ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched = stitched.reset_index(drop=True)\n",
    "sexage_df = sexage_df.reset_index(drop=True)\n",
    "result = pd.concat([stitched, sexage_df], axis=1, join=\"inner\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in sexage_df:\n",
    "#     stitched[col] = sexage_df[col]\n",
    "\n",
    "result.columns = [c[0]  for c in result.columns]\n",
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = result.rename(columns={\"A\": \"Age\", \"S\": \"Sex\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save off file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "filepath = '../open_work/internal_results/StrokeMRI_stitched.csv' \n",
    "result.to_csv(filepath)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.session.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SO here there was no need to filter on session. We got lucky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
