{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data check\n",
    "We will take a look at data sent in January 2024 (loaded into unprocessed); then look at it again after processing is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## The notebooks in this folder deal with new datasets. This is a temporary notebok to discuss the data we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## There are unprocessed (except dropping two columns with deep wm ) harmonizeddatasets we will look at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import sys\n",
    "import glob\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config\n",
    "import cvasl.harmony as har\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unprocessed Datasets for this work\n",
    "EDIS_path =    'our_datasets_unprocessed/EDIS/'\n",
    "HELIUS_pat =   'our_datasets_unprocessed/HELIUS/'\n",
    "Insight46_path='our_datasets_unprocessed/Insight46/'\n",
    "SABRE_path =   'our_datasets_unprocessed/SABRE/'\n",
    "MRI_path =     'our_datasets_unprocessed/StrokeMRI/'\n",
    "TOP_path =     'our_datasets_unprocessed/TOP/'\n",
    "file_name = 'TrainingDataComplete.csv'\n",
    "\n",
    "TOP_file = os.path.join(TOP_path, file_name)\n",
    "MRI_file = os.path.join(MRI_path, file_name)\n",
    "EDIS_file = os.path.join(EDIS_path, file_name)\n",
    "#HELIUS_file = os.path.join(HELIUS_path, file_name)\n",
    "Insight46_file = os.path.join(Insight46_path, file_name)\n",
    "SABRE_file = os.path.join(SABRE_path, file_name)\n",
    "\n",
    "EDIS = pd.read_csv(EDIS_file)\n",
    "#HELIUS = pd.read_csv(HELIUS_file)\n",
    "Insight46 = pd.read_csv(Insight46_file)\n",
    "SABRE = pd.read_csv(SABRE_file)\n",
    "TOP = pd.read_csv(TOP_file)\n",
    "MRI = pd.read_csv(MRI_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #example old datasets\n",
    "# filepath_mri_old = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename_mri_old = os.path.join(filepath_mri_old,'StrokeMRI_pvc2c.csv') \n",
    "# filepath_top_old = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename_top_old = os.path.join(filepath_top_old,'TOP_pvc2c.csv') \n",
    "# TOP_old = pd.read_csv(filename_top_old)\n",
    "# StrokeMRI_old = pd.read_csv(filename_mri_old)\n",
    "# TOP_old = TOP_old.drop(TOP_old.columns[0],axis=1)\n",
    "# StrokeMRI_old = StrokeMRI_old.drop(StrokeMRI_old.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2110714-8b98-45a7-9ad9-5b41166757dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SO one minor note...this was not what we agreed to. We agreed to everything lower case but this was already fixed with the harmonizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we must discuss this with scientists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Examine what harmonization outcomes are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "negs = har.negative_harm_outcomes(\n",
    "    'harmonizations/harm_results',\n",
    "    'csv',\n",
    "    number_columns=[\n",
    "        'sex',\n",
    "        'gm_vol',\n",
    "        'wm_vol',\n",
    "        'csf_vol',\n",
    "        'gm_icvratio',\n",
    "        'gmwm_icvratio',\n",
    "        'wmhvol_wmvol',\n",
    "        'wmh_count',\n",
    "        #'deepwm_b_cov',\n",
    "        'aca_b_cov',\n",
    "        'mca_b_cov',\n",
    "        'pca_b_cov',\n",
    "        'totalgm_b_cov',\n",
    "        #'deepwm_b_cbf',\n",
    "        'aca_b_cbf',\n",
    "        'mca_b_cbf',\n",
    "        'pca_b_cbf',\n",
    "        'totalgm_b_cbf',]\n",
    ") \n",
    "#negs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# negs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9578d5-27ac-4a32-9e07-241921ed2d92",
   "metadata": {},
   "source": [
    "# we were asked to preprocess before performing the harmonization.\n",
    "\n",
    "Therefore we will make the files in our_data which create these proprocessed and deposited into the folder named holder_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce5ecfa-4b50-482b-9164-d79616f0dcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    folder,\n",
    "    file_extension,\n",
    "    outcome_folder,\n",
    "    log_columns=[],\n",
    "    plus_one_log_columns = []\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    This function given a directory will\n",
    "    search all subdirectory for noted file extension\n",
    "    Copies of the files will be processed as specified\n",
    "    which is the specified columns turned to log or +1 then log\n",
    "    then put in the outcome folder\n",
    "    \"\"\"\n",
    "    if not os.path.exists(outcome_folder):\n",
    "            os.makedirs(outcome_folder)\n",
    "    files = '**/*.' + file_extension\n",
    "\n",
    "    suspects = glob.glob(\n",
    "        os.path.join(folder, files),\n",
    "        recursive=True,\n",
    "    )\n",
    "    read_names = []\n",
    "    for file in suspects:\n",
    "        read = pd.read_csv(file, index_col=0)\n",
    "        filenames1 = os.path.split(file)[0]\n",
    "        filenames = os.path.split(filenames1)[-1]\n",
    "        if not os.path.exists(os.path.join(outcome_folder, filenames)):\n",
    "            os.makedirs(os.path.join(outcome_folder, filenames))\n",
    "        read_name = os.path.join(outcome_folder, filenames, os.path.basename(file).split('/')[-1])\n",
    "        read[plus_one_log_columns] = read[plus_one_log_columns].apply(lambda x: x + 1, axis=1)\n",
    "        read[plus_one_log_columns] = read[plus_one_log_columns].apply(lambda x: np.log(x), axis=1)\n",
    "        read[log_columns] = read[log_columns].apply(lambda x: np.log(x), axis=1)\n",
    "        read.to_csv(read_name)\n",
    "        read_names.append(read_name)\n",
    "    return read_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707ed18-49cb-4925-a9f1-f527759257e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep.preprocess('our_datasets_unprocessed',\n",
    "           'csv', 'our_datasets_A',\n",
    "           log_cols=['ACA_B_CoV','MCA_B_CoV','PCA_B_CoV','TotalGM_B_CoV'],\n",
    "           plus_one_log_columns = ['WMH_count','WMHvol_WMvol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76308e0-6af0-493c-bae2-408e194eeaff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outcome_folder = 'outcometrial2/EDIS'\n",
    "show_sample = os.path.join(outcome_folder,'TrainingDataComplete.csv')\n",
    "show = pd.read_csv(show_sample, index_col=0)\n",
    "show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74626f4a-09e1-4d6c-b8f6-bec81f76808c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b6675-8d84-49f5-aa5e-f9f6462cb495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin = pd.read_csv('special\\TrainingDataComplete.csv')\n",
    "origin[['ACA_B_CoV','MCA_B_CoV','PCA_B_CoV','TotalGM_B_CoV']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4496c36-a002-4ab9-bf21-09f6155fa6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
