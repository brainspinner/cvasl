{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploring TSV files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import glob\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "# import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "# from ipywidgets import IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "from cvasl import file_handler as fh # \n",
    "from cvasl import mold #\n",
    "from cvasl import carve\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Configure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_file()\n",
    "root_mri_directory = config.get_directory('raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_pattern = os.path.join(root_mri_directory, '**/*.tsv')\n",
    "tsv_files = glob.glob(tsv_pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### check tsv files \n",
    "Optional commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example = pd.read_csv(tsv_files[0], sep='\\t', header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## check tsv file diversity\n",
    "#tsv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Adding age to analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Now we want to take the csv file with age and add it to the analysis.\n",
    "For now we will hard-code the path, until we decide whether this should be part of the initialized setup on the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "age_csv_place = \"C:/Projects/brainspin/age_data\"\n",
    "age_csv_pattern = os.path.join(age_csv_place, '**/*.csv')\n",
    "age_csv_files = glob.glob(age_csv_pattern, recursive=True)\n",
    "age_dataframe_example1 = pd.read_csv(age_csv_files[0])\n",
    "age_dataframe_example2 = pd.read_csv(age_csv_files[1])\n",
    "age_dataframe_example3 = pd.read_csv(age_csv_files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# superset of ages....must normalize column names and values\n",
    "age_dataframe_example1 = age_dataframe_example1.rename(columns={\"ageatscandate_i46p1\": \"age\",\"participant ID\": \"participant_id\"})\n",
    "age_dataframe_example2 = age_dataframe_example2.rename(columns={\"Age\": \"age\",\"ID\": \"participant_id\", \"Sex\":\"sex\"})\n",
    "age_dataframe_example3 = age_dataframe_example3.rename(columns={\"Age\": \"age\",\"ID\": \"participant_id\", \"Sex\":\"sex\"})\n",
    "age_dataframe_example3 = age_dataframe_example3.drop(\"TP\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stack on top of each otehr\n",
    "frames = [age_dataframe_example1, age_dataframe_example2, age_dataframe_example3]\n",
    "super_age_set = pd.concat(frames)\n",
    "super_age_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Without the subject ages we can not do an analysis on anything except how subjects progress over time points, and how various parameters predict each other. But let's scan all the tev we were given to see if we have ones with age. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Correlations within datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "So now we can make a super-dataset of all the datasets, and see if these correlations hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example2 = pd.read_csv(tsv_files[1], sep='\\t')\n",
    "dataframe_example2.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "More elements than first...let's see what we have in common between the two tsv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first = set(dataframe_example.columns.to_list())\n",
    "second = set(dataframe_example2.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# not_common2 =  list(set(dataframe_example2.columns.to_list()) - set(dataframe_example.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shared = list(first.intersection(second))\n",
    "# shared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Not a lot...let's look at what we have in common in all or most of the tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_file = []\n",
    "longlesses = []\n",
    "for file in tsv_files:\n",
    "    dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "    longness = len(dataframe_example.columns)\n",
    "    name_file.append(file)\n",
    "    longlesses.append(longness)\n",
    "data_tsv = pd.DataFrame([name_file, longlesses])        \n",
    "print(longlesses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "So There may be 15 common features on most as a guess. We need to not look at the last on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(name_file[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_of_relevant_files = name_file[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_file = []\n",
    "longlesses = []\n",
    "intersections = []\n",
    "len_intersections = []\n",
    "for file in set_of_relevant_files:\n",
    "    dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "    longness = len(dataframe_example.columns)\n",
    "    name_file.append(file)\n",
    "    longlesses.append(longness)\n",
    "    dataframe_example2 = pd.read_csv(file, sep='\\t')\n",
    "    columns = dataframe_example2.columns.to_list()\n",
    "    intersection = set(columns).intersection(second)\n",
    "    intersections.append(intersection)\n",
    "    len_intersections.append(len(intersection))\n",
    "data_tsv = pd.DataFrame([name_file, longlesses, len_intersections, intersections])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "So we will have twelve or thireen common elements we can compare.Let's look at hope they are about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_tsv[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_tsv[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tsv[4][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_tsv[4][3].intersection(data_tsv[2][3]).intersection(data_tsv[0][3]).intersection(data_tsv[5][3]).intersection(data_tsv[3][3]).intersection(data_tsv[6][3]).intersection(data_tsv[7][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "OK, so more or less we should have the above values in every group of tsv in our supergroup.\n",
    "Let's check if we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_elements = data_tsv[4][3].intersection(data_tsv[2][3]).intersection(data_tsv[0][3]).intersection(data_tsv[5][3]).intersection(data_tsv[3][3]).intersection(data_tsv[6][3]).intersection(data_tsv[7][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_file = []\n",
    "longlesses = []\n",
    "good_files = []\n",
    "for file in tsv_files:\n",
    "    dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "    if set(list_elements).issubset(set(dataframe_example.columns.to_list())):\n",
    "                                   good_files.append(file)\n",
    "# print(good_files)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(good_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Here we must say in this set, the set of common elements is about:\n",
    "CSV_vol,  'GMWM_ICVRatio',\n",
    " 'GM_ICVRatio',\n",
    " 'GM_vol',\n",
    " 'LongitudinalTimePoint',\n",
    " 'MeanMotion',\n",
    " 'Site',\n",
    " 'SubjectNList',\n",
    " 'WMH_count',\n",
    " 'WMH_vol',\n",
    " 'WM_vol',\n",
    " 'participant_id',\n",
    " 'session'\n",
    " \n",
    " However we need something to extract the common set from any group of tsv columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = fh.extract_common_columns(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_columns_sets = fh.intersect_all(*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we make our super tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "good_columns_list = list(a)\n",
    "good_columns_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we see that every file should have participant_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabs_together = []\n",
    "for file in good_files:\n",
    "    tabular = pd.read_csv(file, sep='\\t',  header=[0,1])\n",
    "    tabularnow = tabular[good_columns_list]\n",
    "    tabs_together.append(tabularnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tabs_together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "tags": []
   },
   "source": [
    "now if tsvs were different we could stack 8 elements of tabular ...and make a supercomparator, but we seem tohave the same tsv over and over because the first ten with thesame columns are the same...wierd check wth scientists..looking at the names they all came from the same day. let's check all dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "So we have three kinds, many times duplicated over- must dicuss with scientists. UNtil then let's reduce and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabs_together[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(tabs_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "properly_different_dataframes = fh.unduplicate_dfs(tabs_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result = result.droplevel(1, axis=1)\n",
    "len(properly_different_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in properly_different_dataframes:\n",
    "    file = file.droplevel(1, axis=1)\n",
    "file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_no_str= file.drop('LongitudinalTimePoint', axis=1)\n",
    "result_no_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "super_age_set = super_age_set.drop(\"TP\", axis= 1)\n",
    "super_age_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here merge with ages\n",
    "final_df = pd.merge(result_no_str,super_age_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.heatmap(final_df.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "So we see a good correlation between grey matter and white matter volumes, and therefore unsurprisingle a good correlation on GMWM-ICVratio and GM_ICV ratio. We also see a great negative correation between CSF volume and GMWM-ICV (also also GM)ICV). These things show our datasets seems to be reflecting expected reality.\n",
    "One next next step is to correlate with age.\n",
    "\n",
    "But let's keep seeing how we can look for things in our tsv.\n",
    "Below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fh.find_where_column(tsv_files, ['CSF_vol', 'WM_vol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Now a coding scientist can continue by finding sets of tsv for specific quesitons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
