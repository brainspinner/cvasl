{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import seaborn\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets into pandas dataframes\n",
    "\n",
    "We have these in our open_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify files\n",
    "datasets_folder = 'C:/Projects/brainspin/not_pushed/data_anonymized/assembled'\n",
    "dataset_files = glob.glob(os.path.join(datasets_folder, '*.csv'))\n",
    "print(dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config.from_file()\n",
    "root_mri_directory = config.get_directory('raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_local = os.path.join(root_mri_directory,'assembled')\n",
    "my_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files into dataframes\n",
    "TOP = pd.read_csv(my_local+'/top_stitched.csv')\n",
    "StrokeMRI = pd.read_csv(my_local+'/StrokeMRI_stitched.csv')\n",
    "Insight46 = pd.read_csv(my_local+'/Insight46_stitched.csv')\n",
    "df_list = [TOP, StrokeMRI, Insight46]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = TOP.drop(0, axis=0)\n",
    "StrokeMRI = StrokeMRI.drop(0, axis=0)\n",
    "Insight46 = Insight46.drop(0, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Insight46_described = Insight46.describe()\n",
    "Insight46_described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI_described = StrokeMRI.describe()\n",
    "StrokeMRI_described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "TOP was produced in a way that made more data non-numeric do extra step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP =  TOP.apply (pd.to_numeric, errors='coerce')\n",
    "TOP_described =TOP.describe()\n",
    "TOP_described"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So datasets are very incomparable by age. We must compare similar age groups. Let's see if we can break the datasets down by age group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to be updated to normalized new standard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_grouped_sex_count = TOP.groupby(['Sex']).count()\n",
    "top_grouped_sex_mean = TOP.groupby(['Sex'])['GM_vol'].mean()\n",
    "#df.groupby([\"state\", \"gender\"])[\"last_name\"].count()\n",
    "top_grouped_sex_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's odd, I though men had bigger brains by volume. Let's see if an age split explains this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_grouped_sex_mean_age = TOP.groupby(['Sex'])['Age'].mean()\n",
    "#df.groupby([\"state\", \"gender\"])[\"last_name\"].count()\n",
    "top_grouped_sex_mean_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "So if women are 1s then they have bigger brains...given that the ages are close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. split out the age groups and compare averages, std, distribution etc. on all parameters\n",
    "-----------------------------------------------------------------------------\n",
    "0. meet to make sure dataframes are in fact correct\n",
    "1a. compare TOP and StrokeMRI only? -> gives us a difference as allowable? gives us baseline on same measurements\n",
    "1b. do a polynomial fits on the error with age (per variability)\n",
    "1c. investigate brain age gap on this (it should be zero)\n",
    "\n",
    "\n",
    "\n",
    "1z. compare Insight46-> every other group's 70+/1 year\n",
    "question of whether Inisght46 people are not truly all healthy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by the way, let's look a little deeper on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skinny = TOP.iloc[:, 5:]\n",
    "df_to_check = top_skinny.dropna()\n",
    "df_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precent_of_variance_explained = .95\n",
    "\n",
    "pca = PCA(n_components=precent_of_variance_explained)\n",
    "\n",
    "pca_data = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# You must normalize the data before applying the fit method\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_to_check)\n",
    "pca = PCA(n_components= df_to_check.shape[1])\n",
    "pca.fit(df_to_check)\n",
    "\n",
    "# Reformat and view results\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "columns=['PC%s' % _ for _ in range(len(df_to_check.columns))],\n",
    "index=df_to_check.columns)\n",
    "print(loadings)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.xlabel('Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, so let's note we have a 94 column dataset , but only about 5 columns are really independant variables by this analysis. \n",
    "let's take a closer look at the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_check.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_akk = df_to_check[df_to_check.columns[:-2]]\n",
    "X = first_akk\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = df_to_check[['Sex']]\n",
    "y = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df['Label']=y\n",
    "##df['Species']=df['Label'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform features\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with df\n",
    "pca_df = pd.DataFrame(X_pca,columns=['PC%s' % _ for _ in range(X.shape[1])])\n",
    "df = pd.merge(df, pca_df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Explained Variance Ratio')\n",
    "for i in range(10):\n",
    "    print('PC{}: {}'.format(i+1,pca.explained_variance_ratio_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.stripplot(x=\"PC1\", y=\"Label\", data=df,jitter=True)\n",
    "plt.title( 'Data Visualized in One Dimension');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lmplot(data=df,x= 'WM_vol', y='GM_vol', hue='Label',fit_reg=False)\n",
    "plt.title('Data Visualized in Two Dimensions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lmplot(data=df,x= 'GM_ICVRatio', y='GMWM_ICVRatio', hue='Label',fit_reg=False)\n",
    "plt.title('Data Visualized in Two Dimensions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lmplot(data=df,x= 'WMH_count', y='WMH_vol', hue='Label',fit_reg=False)\n",
    "plt.title('Data Visualized in Two Dimensions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_variance_explained = .99\n",
    "\n",
    "pca = PCA(n_components=percent_of_variance_explained)\n",
    "\n",
    "pca_data = pca.fit_transform(X)\n",
    "\n",
    "print(\"{} Principal Components are required to explain {} of the variation in this data.\".format(pca.n_components_,percent_of_variance_explained))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler.fit(first_10)\n",
    "pca = PCA(n_components= 4)\n",
    "pca.fit(first_10)\n",
    "\n",
    "# Reformat and view results\n",
    "loadings = pd.DataFrame(pca.components_.T,\n",
    "columns=['PC%s' % _ for _ in range(4)],\n",
    "index=first_10.columns)\n",
    "print(loadings)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.xlabel('Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map= pd.DataFrame(pca.components_,columns=first_10.columns)\n",
    "plt.figure(figsize=(12,6))\n",
    "seaborn.heatmap(map,cmap='rocket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP_tiny = TOP[['GM_vol', 'WM_vol','Age']]\n",
    "# TOP_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroke_tiny = StrokeMRI[['GM_vol', 'WM_vol','Age']]\n",
    "# Stroke_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(Stroke_tiny['Age'],Stroke_tiny['GM_vol'], color='purple')\n",
    "# plt.scatter(TOP['Age'],TOP['GM_vol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relate_columns_graphs_two_dfs(dataframe1, dataframe2, special_column_name, other_column_name):\n",
    "    \"\"\" This function makes a scatter plot of all columns\n",
    "\n",
    "    :param dataframe1: dataframe variable\n",
    "    :type dataframe1: pandas.dataFrame\n",
    "    :param dataframe2: dataframe variable\n",
    "    :type dataframe2: pandas.dataFrame\n",
    "    :param special_column_name: string of column you want to graph against\n",
    "    :type  special_column_name: str\n",
    "\n",
    "    :returns: no return, makes artifact\n",
    "    :rtype: None.\n",
    "    \"\"\"\n",
    "    shared_columns = (dataframe1.columns.intersection(dataframe2.columns)).to_list()\n",
    "    \n",
    "    dataframe1 = dataframe1[shared_columns]\n",
    "    dataframe2 = dataframe2[shared_columns]\n",
    "#     print(dataframe1)\n",
    "    plt.scatter(dataframe1[special_column_name],dataframe1[other_column_name], color='purple', alpha=0.5)\n",
    "    plt.scatter(dataframe2[special_column_name],dataframe2[other_column_name], color = 'orange',alpha=0.5)\n",
    "    plt.xlabel(special_column_name)\n",
    "    plt.ylabel(other_column_name)\n",
    "    #plt.show( block=False )\n",
    "    plt.savefig((other_column_name +\"versus\" + special_column_name + \".png\"))\n",
    "    plt.show( block=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2on2_df(dataframe1, dataframe2, special_column):\n",
    "    shared_columns = (dataframe1.columns.intersection(dataframe2.columns)).to_list()\n",
    "    for rotator_column in dataframe1[shared_columns]:\n",
    "        relate_columns_graphs_two_dfs(dataframe1, dataframe2,special_column, rotator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2on2_df(TOP,StrokeMRI, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_columns = (TOP.columns.intersection(StrokeMRI.columns)).to_list()\n",
    "for rotator_column in TOP[shared_columns]:\n",
    "    relate_columns_graphs_two_dfs(TOP, StrokeMRI,'Age', rotator_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StrokeMRI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TOP.columns.intersection(StrokeMRI.columns)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
