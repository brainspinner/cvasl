{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Exploring TSV files`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import glob\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "from ipywidgets import IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "from cvasl import file_handler as fh # \n",
    "from cvasl import mold #\n",
    "from cvasl import carve\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Configure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config.from_file()\n",
    "root_mri_directory = config.get_directory('raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_pattern = os.path.join(root_mri_directory, '**/*.tsv')\n",
    "tsv_files = glob.glob(tsv_pattern, recursive=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### check tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_mri_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example = pd.read_csv(tsv_files[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## check tsv file diversity\n",
    "tsv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Without the subject ages we can not do an analysis on anything except how subjects progress over time points, and how various parameters predict each other. But let's scan all the tev we were given to see if we have ones with age. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Correlations within datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Let's use one dataframe example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example_nums_only = dataframe_example[[ \n",
    "    'SubjectNList',\n",
    "    'Site', 'GM_vol', 'WM_vol', 'CSF_vol', 'GM_ICVRatio', 'GMWM_ICVRatio',\n",
    "    'WMH_vol', 'WMH_count', 'MeanMotion', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example_nums_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example_nums_only[1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.heatmap(dataframe_example_nums_only[1:].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "So we do see some correlations int his particular dataset that are strong an expected. The area of brain to ICV ratio negatively correlates with the CSF volume as should be expected. White matter and grey matter correlate pretty well. White matter hyperintensities in count correlate somewhat with white matter hyperintensity volume. And deep WM-L correlates between the sides of the brain and both. Basically everything we would expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "So now we can make a super-dataset of all the datasets, and see if these correlations hold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example2 = pd.read_csv(tsv_files[1], sep='\\t')\n",
    "dataframe_example2.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "More elements than first...let's see what we have in common between the two tsv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first = set(dataframe_example.columns.to_list())\n",
    "second = set(dataframe_example2.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_common2 =  list(set(dataframe_example2.columns.to_list()) - set(dataframe_example.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared = list(first.intersection(second))\n",
    "shared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Not a lot...let's look at what we have in common in all or most of the tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_file = []\n",
    "longlesses = []\n",
    "for file in tsv_files:\n",
    "    dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "    longness = len(dataframe_example.columns)\n",
    "    name_file.append(file)\n",
    "    longlesses.append(longness)\n",
    "data_tsv = pd.DataFrame([name_file, longlesses])        \n",
    "print(longlesses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "So There may be 15 common features on most as a guess. We need to not look at the last on the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(name_file[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_of_relevant_files = name_file[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_file = []\n",
    "longlesses = []\n",
    "intersections = []\n",
    "len_intersections = []\n",
    "for file in set_of_relevant_files:\n",
    "    dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "    longness = len(dataframe_example.columns)\n",
    "    name_file.append(file)\n",
    "    longlesses.append(longness)\n",
    "    dataframe_example2 = pd.read_csv(file, sep='\\t')\n",
    "    columns = dataframe_example2.columns.to_list()\n",
    "    intersection = set(columns).intersection(second)\n",
    "    intersections.append(intersection)\n",
    "    len_intersections.append(len(intersection))\n",
    "data_tsv = pd.DataFrame([name_file, longlesses, len_intersections, intersections])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "So we will have twelve or thireen common elements we can compare.Let's look at hope they are about the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_tsv[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below cells no longer relevant, experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_tsv[2][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_tsv[4][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_tsv[4][3].intersection(data_tsv[2][3]).intersection(data_tsv[0][3]).intersection(data_tsv[5][3]).intersection(data_tsv[3][3]).intersection(data_tsv[6][3]).intersection(data_tsv[7][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "OK, so more or less we should have the above values in every group of tsv in our supergroup.\n",
    "Let's check if we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list_elements = data_tsv[4][3].intersection(data_tsv[2][3]).intersection(data_tsv[0][3]).intersection(data_tsv[5][3]).intersection(data_tsv[3][3]).intersection(data_tsv[6][3]).intersection(data_tsv[7][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# name_file = []\n",
    "# longlesses = []\n",
    "# good_files = []\n",
    "# for file in tsv_files:\n",
    "#     dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "#     if set(list_elements).issubset(set(dataframe_example.columns.to_list())):\n",
    "#                                    good_files.append(file)\n",
    "       \n",
    "# print(good_files)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(good_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Here we must say in this set, the set of common elements is about:\n",
    "CSV_vol,  'GMWM_ICVRatio',\n",
    " 'GM_ICVRatio',\n",
    " 'GM_vol',\n",
    " 'LongitudinalTimePoint',\n",
    " 'MeanMotion',\n",
    " 'Site',\n",
    " 'SubjectNList',\n",
    " 'WMH_count',\n",
    " 'WMH_vol',\n",
    " 'WM_vol',\n",
    " 'participant_id',\n",
    " 'session'\n",
    " \n",
    " However we need something to extract the common set from any group of tsv columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def make_columns(list_tsv_files):\n",
    "#     columns_list = []\n",
    "#     for file in list_tsv_files:\n",
    "#         dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "#         columns= dataframe_example.columns.to_list()\n",
    "#         columns_list.append(columns)\n",
    "#     return columns_list\n",
    "\n",
    "# a = fh.make_columns(good_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def intersect_all(*sets):\n",
    "#     result, *rest = sets\n",
    "#     for remaining in rest:\n",
    "#         result = set(result).intersection(remaining)\n",
    "#     return result\n",
    "\n",
    "# good_columns_sets = fh.intersect_all(*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we make our super tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# good_columns_list = list(good_columns_sets)\n",
    "# good_columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tabs_together = []\n",
    "# for file in good_files:\n",
    "#     print(file)\n",
    "#     tabular = pd.read_csv(file, sep='\\t')\n",
    "#     tabularnow = tabular[good_columns_list]\n",
    "#     tabs_together.append(tabularnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tabs_together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "tags": []
   },
   "source": [
    "now if tsvs were different we could stack 8 elements of tabular ...and make a supercomparator, but we seem tohave the same tsv over and over because the first ten with thesame columns are the same...wierd check wth scientists..looking at the names they all came from the same day. let's check all dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# more_files = []\n",
    "# for file in tsv_files:\n",
    "#     dataframe_example = pd.read_csv(file, sep='\\t')\n",
    "#     columns = dataframe_example.columns.to_list()\n",
    "#     if len(columns) > 5:\n",
    "#         more_files.append(file)\n",
    "# b = fh.make_columns(more_files)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# newer_columns_sets = fh.intersect_all(*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_common_columns(list_tsv_files):\n",
    "    b = fh.make_columns(list_tsv_files)\n",
    "    columns_sets = fh.intersect_all(*b)\n",
    "    return columns_sets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fh.extract_common_columns(more_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#newer_columns_sets_list = list(newer_columns_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tabs_together = []\n",
    "# for file in more_files:\n",
    "#     print(file)\n",
    "#     tabular = pd.read_csv(file, sep='\\t')\n",
    "#     tabularnow = tabular[newer_columns_sets_list]\n",
    "#     tabs_together.append(tabularnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tabs_together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "So we have three kinds, many times duplicated over- must dicuss with scientists. UNtil then let's reduce and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tabs_together[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(tabs_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tabs_together[0].equals(tabs_together[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unduplicate_dataframes(list_of_dataframes):\n",
    "    duplicates = []\n",
    "    core = []\n",
    "    for frame,next_frame in zip(list_of_dataframes, list_of_dataframes[1:]):\n",
    "        if frame.equals(next_frame):\n",
    "            duplicates.append(frame)\n",
    "        else:\n",
    "            core.append(frame)\n",
    "    core.append(list_of_dataframes[0])\n",
    "    return core\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unduplicate_dfs(list_of_dataframes):\n",
    "    \"\"\"\n",
    "    This function takes a list of dataframes\n",
    "    and should return only dataframes that are not duplicated from each other\n",
    "    but it must be improved (see TODO)\n",
    "    \"\"\"\n",
    "    # TODO: change to a rotating version so it picks off any duplicates\n",
    "    core = []\n",
    "    for frame,next_frame in zip(list_of_dataframes, list_of_dataframes[1:]):\n",
    "        if frame.equals(next_frame) == False:\n",
    "            core.append(frame)\n",
    "    core.append(list_of_dataframes[0])\n",
    "    return core\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#properly_different_dataframes = fh.unduplicate_dfs(tabs_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check =  unduplicate_dfs(tabs_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bad_lines_out = []\n",
    "# for frame in properly_different_dataframes:\n",
    "#     frame = frame[1:]\n",
    "#     bad_lines_out.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result = pd.concat(bad_lines_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result_no_str= result.drop('LongitudinalTimePoint', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# sns.heatmap(result_no_str.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "So we see a good correlation between grey matter and white matter volumes, and therefore unsurprisingle a good correlation on GMWM-ICVratio and GM_ICV ratio. We also see a great negative correation between CSF volume and GMWM-ICV (also also GM)ICV). These things show our datasets seems to be reflecting expected reality.\n",
    "The next step is to correlate with age."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
