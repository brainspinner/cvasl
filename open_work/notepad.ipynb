{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notepad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be processed using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import glob\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import copy     # Can Copy and Deepcopy files so original file is untouched.\n",
    "from ipywidgets import IntSlider, Output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "import hashlib\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "from cvasl import file_handler as fh # \n",
    "from cvasl import mold #\n",
    "from cvasl import carve\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dicom stripping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cvasl.carve import PydicomDicomReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicomfile_directory1 = \"../tests/dicom_example_folder\"\n",
    "source_column = 'file'\n",
    "# reader = PydicomDicomReader(\n",
    "#         exclude_fields=('PatientName',),\n",
    "#     )\n",
    "# source = carve.DirectorySource(dicomfile_directory1, source_column)\n",
    "# df = reader.read(source)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_folder = 'test'\n",
    "# try: \n",
    "#     os.mkdir(output_folder)\n",
    "# except FileExistsError:\n",
    "#     pass \n",
    "\n",
    "# jpg = PydicomDicomReader.rip_out_jpgs(dicomfile_directory1,source,output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hash_folder(origin_folder1, file_extension, made, force=False):\n",
    "    \"\"\"Hashing function to be used by command line.\n",
    "\n",
    "    :param origin_folder1: The string of the folder with files to hash\n",
    "    :type origin_folder1: str\n",
    "    :param file_extension: File extension\n",
    "    :type file_extension: str\n",
    "    :param made: file directory where csv with hashes will be put\n",
    "    :type made: str\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(made, 'hash_output.csv')\n",
    "    df = hash_rash(origin_folder1, file_extension)\n",
    "    if not force:\n",
    "        if os.path.isfile(filepath):\n",
    "            return\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(filepath))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    df.to_csv(filepath)\n",
    "\n",
    "# def save_preprocessed(array, out_fname, force):\n",
    "#     \"\"\"\n",
    "#     This function is written to be called by the cli module.\n",
    "#     It stores arrays in a directory.\n",
    "#     \"\"\"\n",
    "#     if not force:\n",
    "#         if os.path.isfile(out_fname):\n",
    "#             return\n",
    "#     try:\n",
    "#         os.makedirs(os.path.dirname(out_fname))\n",
    "    # except FileExistsError:\n",
    "    #     pass\n",
    "    # np.save(out_fname, array, allow_pickle=False)\n",
    "\n",
    "\n",
    "def hash_rash(origin_folder1, file_extension):\n",
    "    \"\"\"Hashing function to check files are not corrupted or to assure\n",
    "    files are changed.\n",
    "\n",
    "    :param origin_folder1: The string of the folder with files to hash\n",
    "    :type origin_folder1: str\n",
    "    :param file_extension: File extension\n",
    "    :type file_extension: str\n",
    "\n",
    "    :returns: Dataframe with hashes for what is in folder\n",
    "    :rtype: ~pandas.DataFrame\n",
    "    \"\"\"\n",
    "    hash_list = []\n",
    "    file_names = []\n",
    "    files = '**/*.' + file_extension\n",
    "    \n",
    "    non_suspects1 = glob.glob(\n",
    "        os.path.join(origin_folder1, files),\n",
    "        recursive=True,\n",
    "    )\n",
    "    # print(non_suspects1)\n",
    "    BUF_SIZE = 65536\n",
    "    for file in non_suspects1:\n",
    "        sha256 = hashlib.sha256()\n",
    "        with open(file, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(BUF_SIZE)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha256.update(data)\n",
    "        result = sha256.hexdigest()\n",
    "        hash_list.append(result)\n",
    "        file_names.append(file)\n",
    "        #print(file_names)\n",
    "    df = pd.DataFrame(hash_list, file_names)\n",
    "    df.columns = [\"hash\"]\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={'index': 'file_name'})\n",
    "    #df.to_csv('out.csv')\n",
    "    print(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_2DF():\n",
    "\n",
    "    date = pd.date_range('today', periods=20)\n",
    "    DF1 = pd.DataFrame(np.random.rand(20, 2), index=date)\n",
    "\n",
    "    #DF2 = pd.DataFrame(np.random.rand(20, 4), index=date, columns='A B C D'.split())\n",
    "\n",
    "    return DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DF1 = return_2DF()\n",
    "DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fh.hash_folder('../not_pushed', 'gz', 'hope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_directory = '../not_pushed'\n",
    "file_directory_list = glob.glob(\n",
    "    os.path.join(file_directory, '**/*.tsv'),\n",
    "    recursive=True,\n",
    "    )\n",
    "for file in file_directory_list:\n",
    "            print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the config pathways for the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "root_mri_directory = config.get_directory('raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_pattern = os.path.join(root_mri_directory, '**/*.tsv')\n",
    "tsv_files = glob.glob(tsv_pattern, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example = pd.read_csv(tsv_files[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_pattern = os.path.join(root_mri_directory, '**/*.gz')\n",
    "gz_files = glob.glob(mri_pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gz_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we can use something not in the base environment just to check that these files exist correctly\n",
    "\n",
    "\n",
    "\n",
    "# A path to an mrid brain .nii image:\n",
    "t1_fn = gz_files[0]\n",
    "\n",
    "# Read the .nii image containing the volume with SimpleITK:\n",
    "sitk_t1 = sitk.ReadImage(t1_fn)\n",
    "\n",
    "# and access the numpy array:\n",
    "t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "\n",
    "# now display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly\n",
    "# import plotly.express as px\n",
    "\n",
    "\n",
    "# fig = px.imshow(\n",
    "#     t1,\n",
    "#     facet_col=1,\n",
    "#     animation_frame=0,\n",
    "#     binary_string=True,\n",
    "#     binary_format=\"jpg\",\n",
    "# )\n",
    "# fig.layout.annotations[0][\"text\"] = \"Something0\"\n",
    "# fig.layout.annotations[1][\"text\"] = \"Something2\"\n",
    "# plotly.io.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "data = t1\n",
    "z, x, y = data.nonzero()\n",
    "ax.scatter(x, y, z, c=z, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
