{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Assembling the TOP dataset: partial volume corrected only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook assembles the TOP dataset, however, uses only partial volume corrected values for certain ASL values.\n",
    "This is due to the file set given where no uncorrrected values were in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Read data into pandas dataframe\n",
    "\n",
    "How do we define which files should be used together?\n",
    "options:\n",
    "- all files in folder\n",
    "- based on suffix (e.g. \"n=895_06-Feb-2023_PVC2.tsv\")\n",
    "- check first columns to see whether it matches\n",
    "\n",
    "For now, we will will use the first option, approved by Mathijs on 26th June 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_folder= 'TOP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# We use a config file, you do not have to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is the alternative block to block 3 to run if you have no config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parsed_here = 'C:/your_path/not_pushed/data_anonymized/' # example of a hard-coded path you would feed\n",
    "# config = Config.no_file({ 'bids': parsed_here})\n",
    "# root_directory = config.get_directory('bids')\n",
    "# if os.path.isdir(os.path.join(root_directory, experiment_folder)):\n",
    "#     print(\"this folder exists, we will take tsv from here\")\n",
    "# else: \n",
    "#     print(\"this folder does not seem to exist, try typing again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "config = Config.from_file()\n",
    "root_directory = config.get_directory('raw_data')\n",
    "if os.path.isdir(os.path.join(root_directory, experiment_folder)):\n",
    "    print(\"this folder exists, we will take tsv from here\")\n",
    "else: \n",
    "    print(\"this folder does not seem to exist, try typing again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#root_directory = config.get_directory('raw_data')\n",
    "tsv_path = os.path.join(root_directory, experiment_folder)\n",
    "\n",
    "tsv_files = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('.tsv')]\n",
    "tsv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## we must add code here to handle PVC0 \n",
    "if and only if we later want to cover a set with uncorrected volume (PVC0) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CoV files -> COV values NOT \n",
    "tsv_files_for_cov = []\n",
    "basics = []\n",
    "for file in os.listdir(tsv_path):\n",
    "    if file.startswith('CoV') and file.endswith('.tsv'):\n",
    "        tsv_files_for_cov.append(os.path.join(tsv_path, file))\n",
    "    elif file.endswith('.tsv'):\n",
    "        basics.append(os.path.join(tsv_path, file))\n",
    "basics      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files in selected folder into dataframes\n",
    "cov_dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in tsv_files_for_cov]\n",
    "# make a sample\n",
    "sample_cov_df = cov_dataframes[2] # example of COV file\n",
    "cols_cov = sample_cov_df.columns\n",
    "#look at sample\n",
    "sample_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(sample_cov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files in selected folder into dataframes\n",
    "basic_dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in basics]\n",
    "# make a sample\n",
    "sample_basic_df = basic_dataframes[2] # example of COV file\n",
    "cols_basic = sample_basic_df.columns\n",
    "#look at sample\n",
    "sample_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read ALL files in selected folder into dataframes\n",
    "dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in tsv_files]\n",
    "# make a sample\n",
    "sample_df = dataframes[2] # example of file\n",
    "cols = sample_df.columns\n",
    "#look at sample\n",
    "#sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Below we can see some different columns should be in our final dataframe except sex and age, which we add from another frame.\n",
    "## These lists have some overlap as some values are CoV values that are in are basic values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_all_basic_column = []\n",
    "for frame in basic_dataframes:\n",
    "    list_columns = frame.columns.to_list()\n",
    "    for x in list_columns:\n",
    "        if x not in list_all_basic_column:\n",
    "            list_all_basic_column.append(x)\n",
    "#list_all_basic_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_all_cov_column = []\n",
    "for frame in cov_dataframes:\n",
    "    list_columns = frame.columns.to_list()\n",
    "    for x in list_columns:\n",
    "        if x not in list_all_cov_column:\n",
    "            list_all_cov_column.append(x)\n",
    "#list_all_cov_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Below a function for COV columns to add _cov to name if units are SD/mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "tags": []
   },
   "source": [
    "# need to get all cov_columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we transform one of the COV, we need to transform all of them\n",
    "for frame in cov_dataframes:\n",
    "    print(frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_0 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', #\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'DeepWM_B' : 'DeepWM_B_cov',\n",
    "    'DeepWM_L' : 'DeepWM_L_cov',\n",
    "    'DeepWM_R' : 'DeepWM_R_cov',\n",
    "       }\n",
    "dict_1 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', #\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'ACA_B' : 'ACA_B_cov',\n",
    "    'ACA_L' : 'ACA_L_cov',\n",
    "    'ACA_R' : 'ACA_R_cov',\n",
    "    'MCA_B' : 'MCA_B_cov',\n",
    "    'MCA_L' : 'MCA_L_cov',\n",
    "    'MCA_R' : 'MCA_R_cov',\n",
    "    'PCA_B' : 'PCA_B_cov',\n",
    "    'PCA_L' : 'PCA_L_cov',\n",
    "    'PCA_R' : 'PCA_R_cov',\n",
    "       }\n",
    "dict_2 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', #\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'ACA_proximal_B' : 'ACA_proximal_B_cov', #\n",
    "    'ACA_proximal_L' : 'ACA_proximal_L_cov', #\n",
    "    'ACA_proximal_R' : 'ACA_proximal_R_cov', #\n",
    "    'ACA_intermediate_B' : 'ACA_intermediate_B_cov' ,#\n",
    "    'ACA_intermediate_L' : 'ACA_intermediate_L_cov' ,#\n",
    "    'ACA_intermediate_R' : 'ACA_intermediate_R_cov' ,#\n",
    "    'ACA_distal_B' : 'ACA_distal_B_cov', #\n",
    "    'ACA_distal_R' : 'ACA_distal_R_cov', #\n",
    "    'MCA_proximal_B' : 'MCA_proximal_B_cov' ,#\n",
    "    'MCA_proximal_L' : 'MCA_proximal_L_cov' ,#\n",
    "    'MCA_proximal_R' : 'MCA_proximal_R_cov' ,#\n",
    "    'MCA_intermediate_B' : 'MCA_intermediate_B_cov',#\n",
    "    'MCA_intermediate_L' : 'MCA_intermediate_L_cov',#\n",
    "    'MCA_intermediate_R' : 'MCA_intermediate_R_cov',#\n",
    "    'MCA_distal_B' : 'MCA_distal_B_cov',#\n",
    "    'MCA_distal_L' : 'MCA_distal_L_cov',#\n",
    "    'MCA_distal_R' : 'MCA_distal_R_cov',#\n",
    "    'PCA_proximal_B' : 'PCA_proximal_B_cov',#\n",
    "    'PCA_proximal_L' : 'PCA_proximal_L_cov',#\n",
    "    'PCA_proximal_R' : 'PCA_proximal_R_cov',#\n",
    "    'PCA_intermediate_B' : 'PCA_intermediate_B_cov',#\n",
    "    'PCA_intermediate_L' : 'PCA_intermediate_L_cov',\n",
    "    'PCA_intermediate_R' : 'PCA_intermediate_R_cov',\n",
    "    'PCA_distal_B' : 'PCA_distal_B_cov',\n",
    "    'PCA_distal_L' : 'PCA_distal_L_cov',\n",
    "    'PCA_distal_R' : 'PCA_distal_R_cov',\n",
    "       }\n",
    "dict_3 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', #\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'TotalGM_B' : 'TotalGM_B_cov',\n",
    "    'TotalGM_L' : 'TotalGM_L_cov',\n",
    "    'TotalGM_R' : 'TotalGM_R_cov',\n",
    "       }\n",
    "cov_dataframes[0].rename(columns=dict_0,\n",
    "          inplace=True)\n",
    "cov_dataframes[1].rename(columns=dict_1,\n",
    "          inplace=True)\n",
    "cov_dataframes[2].rename(columns=dict_2,\n",
    "          inplace=True)\n",
    "cov_dataframes[3].rename(columns=dict_3,\n",
    "          inplace=True)\n",
    "cov_dataframes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Below we take all the dataframes and put them into tsv files in a specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cov_dataframes[3].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbr = 0\n",
    "for frame in cov_dataframes:\n",
    "    filepath = '../open_work/internal_results/stitchy/cov' \n",
    "    filename = os.path.join(filepath,str(numbr+1)) \n",
    "    if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "        os.makedirs(filepath)\n",
    "    frame.to_csv((filename +'.tsv'), sep=\"\\t\")\n",
    "    numbr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbr = 0\n",
    "for frame in basic_dataframes:\n",
    "    filepath = '../open_work/internal_results/stitchy/basics' \n",
    "    filename = os.path.join(filepath,str(numbr+1)) \n",
    "    if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "        os.makedirs(filepath)\n",
    "    frame.to_csv((filename +'.tsv'), sep=\"\\t\")\n",
    "    numbr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cov_tsv_folder_made = '../open_work/internal_results/stitchy/cov'\n",
    "cov_identical_columns = sep.check_identical_columns(cov_tsv_folder_made)\n",
    "cov_identical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basics_tsv_folder_made = '../open_work/internal_results/stitchy/basics'\n",
    "basics_identical_columns = sep.check_identical_columns(basics_tsv_folder_made)\n",
    "basics_identical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we need to make a super dataframes list\n",
    "super_dataframes = basic_dataframes +cov_dataframes\n",
    "len(super_dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Copy identical columns from any file\n",
    "\n",
    "we could also read it from the data, but if it's always the same, we can just define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tsv_folder_made = '../open_work/internal_results/stitchy'\n",
    "identical_columns = sep.check_identical_columns(basics_tsv_folder_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#identical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched = sample_basic_df[identical_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(stitched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_identical = stitched.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Here is where we add the different parts to stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in super_dataframes:\n",
    "    for col in df.columns[n_identical:]:\n",
    "        stitched[col] = df[col]\n",
    "\n",
    "stitched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(stitched.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Here we can should get rid of second visits, but what we see is that session was not in the common columns. We will NOT get rid of all second time points, and people ending in _2. And mention to scientists..turns out to be a mute point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stitched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can get rid of double header\n",
    "stitched = stitched[1:]\n",
    "#stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['session'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['LongitudinalTimePoint'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### so due the fact they are all on first visit, first session, we can write this into p[atient id LATER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## So in this dataset we have one longitudinal timepoint, and one type of session. no need to filter down away from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_path = os.path.join(root_directory, 'age_data', 'Age_sex_TOP.csv')\n",
    "sexage_df = pd.read_csv(sexage_path, index_col=0)\n",
    "print(len(sexage_df))\n",
    "sexage_df['renumber'] = sexage_df.index\n",
    "sexage_df['renumber'] = sexage_df['renumber'].apply(str)\n",
    "sexage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Here we take the patient ID and align it with our other frame's index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched = stitched.reset_index(drop=False)\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(stitched.participant_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['renumber'] = stitched['participant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df = sexage_df.reset_index(drop=True)\n",
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#stitched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = stitched.merge(sexage_df, on=\"renumber\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case there are duplicates in there\n",
    "result = result.loc[:,~result.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "## Conform file to new standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "### example of new standard (from M.D. on 23/08/2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_path = '../researcher_interface/sample_sep_values/showable_standard.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard = pd.read_csv(standard_path)\n",
    "set_standard = set(standard.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.columns = result.columns.str.lower()\n",
    "set_results= set(result.columns.to_list())\n",
    "\n",
    "z = set_results.intersection(set_standard) \n",
    "#z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in result.columns:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shift column 'Name' to first position\n",
    "first_column = result.pop('participant_id')\n",
    "  \n",
    "# insert column using insert(position,column_name,\n",
    "# first_column) function\n",
    "result.insert(0, 'participant_id', first_column)\n",
    "result['participant_id'] = result['participant_id']+'_ses-1_run-1'\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#standard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['session_id'] = result['session']\n",
    "second_column = result.pop('session_id')\n",
    "result.insert(1, 'session_id', second_column)\n",
    "result['site'] = \"TOP\"\n",
    "result['run_id'] = result['longitudinaltimepoint']\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#standard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['gm_icv_ratio'] = result['gm_icvratio']\n",
    "result['gmwm_icv_ratio'] = result['gmwm_icvratio']\n",
    "result['cbf_gm_pvc0'] = 'NaN' \n",
    "result['cbf_gm_pvc2']=  result['totalgm_b'] \n",
    "result['cbf_wm_pvc0']= 'NaN'\n",
    "result['cbf_wm_pvc2']= result['deepwm_b']\n",
    "result['cbf_aca_pvc0'] =  'NaN'\n",
    "result['cbf_mca_pvc0']  = 'NaN'\n",
    "result['cbf_pca_pvc0'] =  'NaN'\n",
    "result['cbf_aca_pvc2']  = result['aca_b']\n",
    "result['cbf_mca_pvc2']  = result['mca_b']\n",
    "result['cbf_pca_pvc2']  = result['pca_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for - need to check with student and scientists!\n",
    "result['cov_gm_pvc0'] =  'NaN' # correct does not exist\n",
    "# result['cov_gm_pvc2']  = result[]\n",
    "result['cov_wm_pvc0']  = 'NaN' # does not exist\n",
    "# result['cov_wm_pvc2']  = result[]\n",
    "result['cov_aca_pvc0'] =  'NaN'# does not exist\n",
    "result['cov_mca_pvc0']  = 'NaN'# does not exist\n",
    "result['cov_pca_pvc0']  = 'NaN'# does not exist\n",
    "result['cov_aca_pvc2'] = result['aca_b_cov']\n",
    "result['cov_mca_pvc2'] = result['mca_b_cov']\n",
    "result['cov_pca_pvc2'] = result['pca_b_cov']\n",
    "\n",
    "\n",
    "     # 'ACA_proximal_B_cov',\n",
    "     #   'ACA_proximal_L_cov', 'ACA_proximal_R_cov', 'ACA_intermediate_B_cov',\n",
    "     #   'ACA_intermediate_L_cov', 'ACA_intermediate_R_cov', 'ACA_distal_B_cov',\n",
    "     #   'ACA_distal_R_cov', 'MCA_proximal_B_cov', 'MCA_proximal_L_cov',\n",
    "     #   'MCA_proximal_R_cov', 'MCA_intermediate_B_cov',\n",
    "     #   'MCA_intermediate_L_cov', 'MCA_intermediate_R_cov', 'MCA_distal_B_cov',\n",
    "     #   'MCA_distal_L_cov', 'MCA_distal_R_cov', 'PCA_proximal_B_cov',\n",
    "     #   'PCA_proximal_L_cov', 'PCA_proximal_R_cov', 'PCA_intermediate_B_cov',\n",
    "     #   'PCA_intermediate_L_cov', 'PCA_intermediate_R_cov', 'PCA_distal_B_cov',\n",
    "     #   'PCA_distal_L_cov', 'PCA_distal_R_cov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in result.columns:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we added a bunch of columns \n",
    "len(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set_results= set(result.columns.to_list())\n",
    "\n",
    "# z = set_results.intersection(set_standard) \n",
    "# new_result_columns = []\n",
    "# for listable in z:\n",
    "#     new_result_columns.append(listable)\n",
    "# new_results = result[new_result_columns]\n",
    "# new_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard.columns[:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_results = new_results[standard.columns[:33]]\n",
    "# new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {0:'F',1:'M',}\n",
    "results = result.assign(sex = result.sex.map(sex_mapping))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## here need to reorder the columns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shift columns to  position\n",
    "third_column = results.pop('run_id')\n",
    "fourth_column = results.pop('age')\n",
    "fifth_column = results.pop('sex')\n",
    "sixth_column = results.pop('site')\n",
    "seventh_column = results.pop('gm_vol')\n",
    "eight_column = results.pop('wm_vol')\n",
    "ninth_column = results.pop('csf_vol')\n",
    "tenth_column = results.pop('gm_icv_ratio')\n",
    "eleventh_column = results.pop('gmwm_icv_ratio')\n",
    "twelvth_column = results.pop('wmh_vol')\n",
    "thirteenth_column = results.pop('wmh_count')\n",
    "\n",
    "#last_column = results.pop('index')\n",
    "\n",
    "results.insert(2, 'run_id', third_column)\n",
    "results.insert(3, 'age', fourth_column)\n",
    "results.insert(4, 'sex', fifth_column)\n",
    "results.insert(5, 'site', sixth_column)\n",
    "results.insert(6, 'gm_vol', seventh_column)\n",
    "results.insert(7, 'wm_vol', eight_column)\n",
    "results.insert(8, 'csf_vol', ninth_column)\n",
    "results.insert(9, 'gm_ivc_ratio',tenth_column)\n",
    "results.insert(10, 'gmwm_ivc_ratio',eleventh_column)\n",
    "results.insert(11, 'wmh_vol',twelvth_column)\n",
    "results.insert(12, 'wmh_count',thirteenth_column)\n",
    "#results.insert(82, 'index', last_column)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = results.drop(['index', 'subjectnlist','session','longitudinaltimepoint', 'tp','gmwm_icvratio','gm_icvratio'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for column in results.columns:\n",
    "#     print(column, type(results[column][9]))\n",
    "standard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in results.columns:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(results.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "## now take last 20 columns, and put them after wmh count\n",
    "## generally reorder columns!\n",
    "not done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head_columns = results.columns[:13]\n",
    "middle_columns = results.columns[13:97]\n",
    "tail_columns = results.columns[97:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results = pd.concat([results[head_columns],results[tail_columns],results[middle_columns]], axis=1)\n",
    "f_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in f_results.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in f_results.columns[6:]:\n",
    "    #print(column)\n",
    "    f_results[column] = pd.to_numeric(f_results[column], errors = 'coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep.check_sex_dimorph_expectations(f_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(f_results.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # maybe examine bigger graphs?\n",
    "# numeric_results = results.iloc[:, 2:55]\n",
    "# numeric_results = numeric_results.drop('sex', axis= 1) \n",
    "# numeric_results = numeric_results.drop('site', axis= 1) \n",
    "# #numeric_results = numeric_results.drop('renumber', axis= 1) \n",
    "# #numeric_results = numeric_results.dropna(axis=0) \n",
    "# sep.relate_columns_graphs(numeric_results, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep.relate_columns_graphs_numeric(f_results, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doubled_outliers =sep.find_outliers_by_list(f_results, f_results.columns.to_list()[6:], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doubled_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "## Save outlier for M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../open_work/internal_results' \n",
    "filename = os.path.join(filepath,'more_possible_outliers.csv') \n",
    "if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "    os.makedirs(filepath)\n",
    "doubled_outliers.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "## Save off file of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../open_work/internal_results' \n",
    "filename = os.path.join(filepath,'top_stitched_conformed.csv') \n",
    "if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "    os.makedirs(filepath)\n",
    "f_results.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in f_results.columns: \n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_results[['gm_ivc_ratio','gmwm_ivc_ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
