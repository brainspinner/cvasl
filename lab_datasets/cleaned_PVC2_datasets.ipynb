{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Clean PVC2 datasets\n",
    "\n",
    "This notebooks takes the TOP, Stroke MRI, Insight 46 and SABRE datasets, and cleans them down to the relavant parameters for an ML model using only corrected ASL values.\n",
    "\n",
    "Then we show some preliminary correlations and ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# demo stuff\n",
    "import ipywidgets as widgets\n",
    "import seaborn \n",
    "\n",
    "# ml stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclean_TOP = pd.read_csv('../open_work/internal_results/top_stitched_conformed.csv ')\n",
    "unclean_StrokeMRI = pd.read_csv('../open_work/internal_results/mri_stitched_conformed.csv')\n",
    "unclean_Insight46 = pd.read_csv('../open_work/internal_results/inisight46_all_stitched_conformed.csv')\n",
    "unclean_SABRE = pd.read_csv('../open_work/internal_results/SABRE_pvc2_stitched_conformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(unclean_Insight46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unclean_TOP.head(130).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_of_parameters = [\n",
    "    'participant_id', \n",
    "    'age',\n",
    "    'sex',\n",
    "    'gm_vol',\n",
    "    'wm_vol',\n",
    "    'csf_vol',\n",
    "    'gm_ivc_ratio',\n",
    "    'gmwm_ivc_ratio',\n",
    "    'wmh_vol',\n",
    "    'wmh_count',\n",
    "    'deepwm_b_cov',\n",
    "    'aca_b_cov',\n",
    "    'mca_b_cov',\n",
    "    'pca_b_cov',\n",
    "    'totalgm_b_cov',\n",
    "    'deepwm_b', # we presume this is cbf, needs a check\n",
    "    'aca_b', # we presume this is cbf, needs a check\n",
    "    'mca_b', # we presume this is cbf, needs a check\n",
    "    'pca_b', # we presume this is cbf, needs a check\n",
    "    'totalgm_b', # we presume this is cbf, needs a check\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = unclean_TOP[list_of_parameters]\n",
    "StrokeMRI = unclean_StrokeMRI[list_of_parameters]\n",
    "Insight46 = unclean_Insight46[list_of_parameters]\n",
    "SABRE = unclean_SABRE[list_of_parameters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's drop all our NAN rows from each dataframe\n",
    "TOP =   TOP.dropna()\n",
    "StrokeMRI = StrokeMRI.dropna()#\n",
    "Insight46 = Insight46.dropna()#\n",
    "SABRE =  SABRE.dropna()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now let's drop the two from TOP we know are problematic\n",
    "# subject 239 and 1038\n",
    "TOP.head(450).tail(50)\n",
    "filtered_bad1 = TOP[TOP[\"participant_id\"].str.contains(\"sub-0239_1_ses-1_run-1\")]\n",
    "filtered_bad2 = TOP[TOP[\"participant_id\"].str.contains(\"1038\")]\n",
    "print(filtered_bad1, filtered_bad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP =TOP.drop([87,442])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we will clean the strokeMRI dataset\n",
    "#StrokeMRI.head(450).tail(50)\n",
    "\n",
    "filtered_bad_mri = StrokeMRI[StrokeMRI[\"participant_id\"].str.contains(\"59365\")]\n",
    "print(filtered_bad_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI =StrokeMRI.drop([470,471])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TOP = TOP.drop(TOP.columns[0],axis=1)\n",
    "# StrokeMRI =StrokeMRI.drop(StrokeMRI.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for f in SABRE.participant_id:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_bad_sabre = SABRE[SABRE[\"participant_id\"].str.contains( \"180106|164058|24646|501418|600137|502441|265542|225223|95329|68503|34935|229151|501636|500904|373519|256870|24328|234940|2341\")]\n",
    "print(filtered_bad_sabre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SABRE = SABRE.drop(list(filtered_bad_sabre.index))\n",
    "#SABRE.tail(600).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we have a clean TOP and StrokeMRI with sex mapped correctly, we can now look at out datasets for correlations;\n",
    "\n",
    "let's save off the PVC2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filepath = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename = os.path.join(filepath,'SABRE_pvc2_cleaned.csv') \n",
    "# if not os.path.exists(filepath):\n",
    "#     # if filder doesn't exist, create it\n",
    "#     os.makedirs(filepath)\n",
    "# SABRE.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filepath = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename = os.path.join(filepath,'Insight46_pvc2c.csv') \n",
    "# if not os.path.exists(filepath):\n",
    "#     # if filder doesn't exist, create it\n",
    "#     os.makedirs(filepath)\n",
    "# Insight46.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filepath = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename = os.path.join(filepath,'TOP_pvc2c.csv') \n",
    "# if not os.path.exists(filepath):\n",
    "#     # if filder doesn't exist, create it\n",
    "#     os.makedirs(filepath)\n",
    "# TOP.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filepath = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "# filename = os.path.join(filepath,'StrokeMRI_pvc2c.csv') \n",
    "# if not os.path.exists(filepath):\n",
    "#     # if filder doesn't exist, create it\n",
    "#     os.makedirs(filepath)\n",
    "# StrokeMRI.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## pick and visualize correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#our_data = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = widgets.SelectMultiple(\n",
    "    options=TOP.columns.tolist(),\n",
    "    value=['gm_vol'],\n",
    "    #rows=10,\n",
    "    description='Features',\n",
    "    disabled=False\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_list = list(features.value)\n",
    "\n",
    "features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Note you can also just hard-code in your picked features\n",
    "\n",
    "['gm_vol', 'wm_vol', 'csf_vol', 'gm_ivc_ratio', 'gmwm_ivc_ratio', 'wmh_vol']\n",
    "gives a pretty good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now choose a label\n",
    "label = widgets.Dropdown(\n",
    "    options= TOP.columns.tolist(),# our_data.columns.tolist(),\n",
    "    value='age',\n",
    "    #rows=10,\n",
    "    description='label',\n",
    "    disabled=False\n",
    ")\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_column = [label.value]\n",
    "full_matrix = features_list + x_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP[full_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Note: pandas will default correlation method to ='pearson'. Needs discussion with scientsts if other correlation is better. Types kendall and spearman are avalable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we need to flip the sex back to numbers for a correlation\n",
    "sex_mapping = {'F':0,'M':1}\n",
    "TOP = TOP.assign(sex = TOP.sex.map(sex_mapping))\n",
    "TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seaborn.heatmap(TOP[full_matrix].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Now a lot of exciting correlations with everything.. \n",
    "Not everything correlates well but we see age correlations with GM volume, and negatively\n",
    "This is what we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_matrix = TOP[full_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = ml_matrix.drop('age', axis =1)\n",
    "X = X.values\n",
    "X = X.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = ml_matrix['age'].values\n",
    "y=y.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # scale\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Maybe we want a drop down to pick the algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linr = LinearRegression()\n",
    "linr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = linr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, y_pred, c='crimson')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## So why not just train on all features and see if it is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_matrix = TOP.drop('participant_id', axis=1)\n",
    "X = ml_matrix.drop('age', axis =1)\n",
    "X = X.values\n",
    "X = X.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = ml_matrix['age'].values\n",
    "y=y.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # scale\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_train = sc.transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linr = LinearRegression()\n",
    "linr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = linr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, y_pred, c='crimson')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llreg = linear_model.LassoLars(alpha=0.01)\n",
    "llreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = llreg.predict(X_test)\n",
    "print('R2 score Linear regression: %.3f' % llreg.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# So now we have our simple baseline model, and we can save it and apply to the other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saving =widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Click me to save model',\n",
    "    disabled=False,\n",
    "    button_style='success', #\n",
    "    tooltip='Description',\n",
    "    icon='check' # \n",
    ")\n",
    "\n",
    "saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if saving.value:\n",
    "    print('You need to name your file, then hit enter')\n",
    "    file_given_name = input()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if model folder exists and if not , then create\n",
    "model_folder = '../result_models/'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "# optional model saving below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save off file\n",
    "joblib.dump(linr, ('../result_models/'+file_given_name+ '.sav'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "# Baseline model is at '../result_models/TOP_based_lr.sav'\n",
    "\n",
    "Simplest Linear Regression\n",
    "\n",
    "R2 score Linear regression: 0.576\n",
    "\n",
    "Explained variance score: 0.577\n",
    "\n",
    "The mean absolute error: 5.181"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "now we can ask how this does with our other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sex_mapping = {'F':0,'M':1}\n",
    "StrokeMRI = StrokeMRI.assign(sex = StrokeMRI.sex.map(sex_mapping))\n",
    "StrokeMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_ml_matrix = StrokeMRI.drop('participant_id', axis=1)\n",
    "X_mri = mri_ml_matrix.drop('age', axis =1)\n",
    "X_mri = X_mri.values\n",
    "X_mri = X_mri.astype('float')\n",
    "y_mri = mri_ml_matrix['age'].values\n",
    "y_mri=y_mri.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mri_train, X_mri_test, y_mri_train, y_mri_test = train_test_split(X_mri, y_mri, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scale\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_mri_train)\n",
    "# X_mri_train = sc.transform(X_mri_train)\n",
    "# X_mri_test = sc.transform(X_mri_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = linr.predict(X_mri_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#y_mri_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_mri_test, y_mri_pred, c='purple')\n",
    "plt.scatter(y_test, y_pred, c='yellow')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "p1 = max(max(y_mri_pred), max(y_mri_test))\n",
    "p2 = min(min(y_mri_pred), min(y_mri_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.title('TOP based model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is bad... we need to understand where this went off. In the end wea will probably make a mixed model, but"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = llreg.predict(X_mri_test)\n",
    "print('R2 score Lasso regression: %.3f' % llreg.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_mri_test, y_mri_pred, c='crimson')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "p1 = max(max(y_mri_pred), max(y_mri_test))\n",
    "p2 = min(min(y_mri_pred), min(y_mri_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seaborn.heatmap(StrokeMRI[['age', 'sex', 'gm_vol', 'wm_vol', 'csf_vol',\n",
    "       'gm_ivc_ratio', 'gmwm_ivc_ratio', 'wmh_vol', 'wmh_count',\n",
    "       'deepwm_b_cov', 'aca_b_cov', 'mca_b_cov', 'pca_b_cov', 'totalgm_b_cov',\n",
    "       'deepwm_b', 'aca_b', 'mca_b', 'pca_b', 'totalgm_b']].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seaborn.heatmap(TOP[['age', 'sex', 'gm_vol', 'wm_vol', 'csf_vol',\n",
    "       'gm_ivc_ratio', 'gmwm_ivc_ratio', 'wmh_vol', 'wmh_count',\n",
    "       'deepwm_b_cov', 'aca_b_cov', 'mca_b_cov', 'pca_b_cov', 'totalgm_b_cov',\n",
    "       'deepwm_b', 'aca_b', 'mca_b', 'pca_b', 'totalgm_b']].corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP[['age', 'sex', 'gm_vol', 'wm_vol', 'csf_vol',\n",
    "       'gm_ivc_ratio', 'gmwm_ivc_ratio', 'wmh_vol', 'wmh_count',\n",
    "       'deepwm_b_cov', 'aca_b_cov', 'mca_b_cov', 'pca_b_cov', 'totalgm_b_cov',\n",
    "       'deepwm_b', 'aca_b', 'mca_b', 'pca_b', 'totalgm_b']].corr() - StrokeMRI[['age', 'sex', 'gm_vol', 'wm_vol', 'csf_vol',\n",
    "       'gm_ivc_ratio', 'gmwm_ivc_ratio', 'wmh_vol', 'wmh_count',\n",
    "       'deepwm_b_cov', 'aca_b_cov', 'mca_b_cov', 'pca_b_cov', 'totalgm_b_cov',\n",
    "       'deepwm_b', 'aca_b', 'mca_b', 'pca_b', 'totalgm_b']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.age.min(), TOP.age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI.age.min(), StrokeMRI.age.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "let's make a miniStrokeMRI cut down to ages close to TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regressio means we need to map to ints at a minimal, but this is a bad algorithm choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ministroke = StrokeMRI\n",
    "ministroke = ministroke[ministroke['age'] > 59.78]\n",
    "ministroke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {
    "tags": []
   },
   "source": [
    "So about 60% of our data matches the TOP age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mini_ml_matrix = ministroke.drop('participant_id', axis=1)\n",
    "X_mini = mini_ml_matrix.drop('age', axis =1)\n",
    "X_mini = X_mini.values\n",
    "X_mini = X_mini.astype('float')\n",
    "y_mini = mini_ml_matrix['age'].values\n",
    "y_mini=y_mini.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mini_train, X_mini_test, y_mini_train, y_mini_test = train_test_split(X_mini, y_mini, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mini_pred = linr.predict(X_mini_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_mini_test,y_mini_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mini_test, y_mini_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mini_test, y_mini_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The model gets better, but is very off, I suspect we have coded the values differently on some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "TOP still has some outlying data that needs to be cleaned out before the model is made... judging from the maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.describe() - StrokeMRI.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_too_high_by_totalgm =TOP[TOP['deepwm_b'] > 120]\n",
    "top_too_high_by_totalgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_too_low_by_totalgm =TOP[TOP['deepw_b'] <30]\n",
    "top_too_low_by_totalgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP.sort_values('wmh_count', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
