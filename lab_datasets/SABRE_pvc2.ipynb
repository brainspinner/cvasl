{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sabre PVC 2 only data set conglomeration and sewing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Import neccesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_folder= 'SABRE_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config.from_file()\n",
    "root_directory = config.get_directory('raw_data')\n",
    "if os.path.isdir(os.path.join(root_directory, experiment_folder)):\n",
    "    print(\"this folder exists, we will take tsv from here\")\n",
    "else: \n",
    "    print(\"this folder does not seem to exist, try typing again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Filter down to only PVC2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = config.get_directory('raw_data')\n",
    "tsv_path = os.path.join(root_directory, experiment_folder)\n",
    "\n",
    "tsv_files = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('.tsv')]\n",
    "tsv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_files_pvc2 = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('PVC2.tsv')]\n",
    "#tsv_files_pvc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_files_pvc0 = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('PVC0.tsv')]\n",
    "#tsv_files_pvc0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# now we will make only a PVC2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsv_files_for_cov = []\n",
    "basics = []\n",
    "for file in os.listdir(tsv_path):\n",
    "    if file.startswith('CoV') and file.endswith('PVC2.tsv'):\n",
    "        tsv_files_for_cov.append(os.path.join(tsv_path, file))\n",
    "    elif file.endswith('PVC2.tsv'):\n",
    "        basics.append(os.path.join(tsv_path, file))\n",
    "tsv_files_for_cov     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files in selected folder into dataframes\n",
    "cov_dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in tsv_files_for_cov]\n",
    "# make a sample\n",
    "sample_cov_df = cov_dataframes[2] # example of COV file\n",
    "cols_cov = sample_cov_df.columns\n",
    "#look at sample\n",
    "sample_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files in selected folder into dataframes\n",
    "basic_dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in basics]\n",
    "# make a sample\n",
    "sample_basic_df = basic_dataframes[2] # example of COV file\n",
    "cols_basic = sample_basic_df.columns\n",
    "#look at sample\n",
    "sample_basic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read ALL files in selected folder into dataframes\n",
    "dataframes = [pd.read_csv(file, sep='\\t', header=[0]) for file in tsv_files]\n",
    "# make a sample\n",
    "sample_df = dataframes[2] # example of file\n",
    "cols = sample_df.columns\n",
    "#look at sample\n",
    "#sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_all_basic_column = []\n",
    "for frame in basic_dataframes:\n",
    "    list_columns = frame.columns.to_list()\n",
    "    for x in list_columns:\n",
    "        if x not in list_all_basic_column:\n",
    "            list_all_basic_column.append(x)\n",
    "#list_all_basic_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_all_cov_column = []\n",
    "for frame in cov_dataframes:\n",
    "    list_columns = frame.columns.to_list()\n",
    "    for x in list_columns:\n",
    "        if x not in list_all_cov_column:\n",
    "            list_all_cov_column.append(x)\n",
    "#list_all_cov_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we transform one of the COV, we need to transform all of them\n",
    "for frame in cov_dataframes:\n",
    "    print(frame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_0 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', # to here\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'MeanMotion' : 'mean_motion',#\n",
    "    'DeepWM_B' : 'DeepWM_B_cov',\n",
    "    'DeepWM_L' : 'DeepWM_L_cov',\n",
    "    'DeepWM_R' : 'DeepWM_R_cov',\n",
    "       }\n",
    "dict_1 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', # to here\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'MeanMotion' : 'mean_motion',#\n",
    "    'ACA_B' : 'ACA_B_cov',\n",
    "    'ACA_L' : 'ACA_L_cov',\n",
    "    'ACA_R' : 'ACA_R_cov',\n",
    "    'MCA_B' : 'MCA_B_cov',\n",
    "    'MCA_L' : 'MCA_L_cov',\n",
    "    'MCA_R' : 'MCA_R_cov',\n",
    "    'PCA_B' : 'PCA_B_cov',\n",
    "    'PCA_L' : 'PCA_L_cov',\n",
    "    'PCA_R' : 'PCA_R_cov',\n",
    "       }\n",
    "dict_2 = {\n",
    "    'participant_id' : 'participant_id', #\n",
    "    'session' : 'session', #,\n",
    "    'LongitudinalTimePoint' : 'LongitudinalTimePoint', #\n",
    "    'SubjectNList' : 'SubjectNList', #\n",
    "    'Site' : 'Site', #\n",
    "    'GM_vol' : 'GM_vol', #\n",
    "    'WM_vol' : 'WM_vol' ,#\n",
    "    'CSF_vol' : 'CSF_vol', #\n",
    "    'GM_ICVRatio' : 'GM_ICVRatio', #\n",
    "    'GMWM_ICVRatio' : 'GMWM_ICVRatio', # to here\n",
    "    'WMH_vol' : 'WMH_vol',#\n",
    "    'WMH_count' : 'WMH_count', # to here\n",
    "    'MeanMotion' : 'mean_motion',#\n",
    "    'TotalGM_B' : 'TotalGM_B_cov',\n",
    "    'TotalGM_L' : 'TotalGM_L_cov',\n",
    "    'TotalGM_R' : 'TotalGM_R_cov',\n",
    "       }\n",
    "\n",
    "cov_dataframes[0].rename(columns=dict_0,\n",
    "          inplace=True)\n",
    "cov_dataframes[1].rename(columns=dict_1,\n",
    "          inplace=True)\n",
    "cov_dataframes[2].rename(columns=dict_2,\n",
    "          inplace=True)\n",
    "\n",
    "cov_dataframes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbr = 0\n",
    "for frame in cov_dataframes:\n",
    "    filepath = '../open_work/internal_results/stitchy/SABRE_pvc2/cov' \n",
    "    filename = os.path.join(filepath,str(numbr+1)) \n",
    "    if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "        os.makedirs(filepath)\n",
    "    frame.to_csv((filename +'.tsv'), sep=\"\\t\")\n",
    "    numbr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numbr = 0\n",
    "for frame in basic_dataframes:\n",
    "    filepath = '../open_work/internal_results/stitchy/SABRE_pvc2/basics' \n",
    "    filename = os.path.join(filepath,str(numbr+1)) \n",
    "    if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "        os.makedirs(filepath)\n",
    "    frame.to_csv((filename +'.tsv'), sep=\"\\t\")\n",
    "    numbr +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cov_tsv_folder_made = '../open_work/internal_results/stitchy/SABRE_pvc2/cov'\n",
    "cov_identical_columns = sep.check_identical_columns(cov_tsv_folder_made)\n",
    "print(cov_identical_columns)\n",
    "print(len(cov_identical_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basics_tsv_folder_made = '../open_work/internal_results/stitchy/basics'\n",
    "basics_identical_columns = sep.check_identical_columns(basics_tsv_folder_made)\n",
    "print(basics_identical_columns)\n",
    "print(len(basics_identical_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## here we note that our identical columns are not the same between the two datasets...not is one a subset of the other...but could be if we get rid of mean motion\n",
    "\n",
    "So we will get rid of mean motion and add it back later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we need to make a super dataframes list\n",
    "super_dataframes = basic_dataframes +cov_dataframes\n",
    "len(super_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "identical_columns = sep.check_identical_columns(basics_tsv_folder_made)\n",
    "identical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched = sample_basic_df[identical_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_identical = stitched.shape[1]\n",
    "#n_identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the different parts in together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in super_dataframes:\n",
    "    for col in df.columns[n_identical:]:\n",
    "        stitched[col] = df[col]\n",
    "\n",
    "stitched.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(stitched.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we can get rid of double header\n",
    "stitched = stitched[1:]\n",
    "#stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['session'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['LongitudinalTimePoint'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "So in this set we had only one scan per visit, and only one visit per patient. Great..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now we need to find the new sexage_path \n",
    "\n",
    "csv_files = [os.path.join(tsv_path, file) for file in os.listdir(tsv_path) if file.endswith('.csv')]\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df = pd.read_csv(csv_files[0], index_col=0)\n",
    "sexage_df['renumber'] = sexage_df.index\n",
    "sexage_df['renumber'] = sexage_df['renumber'].apply(str)\n",
    "#sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df['TP'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## SO here we have to align the patient IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df.Sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stitched['renumber'] = stitched['participant_id']\n",
    "stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sexage_df = sexage_df.reset_index(drop=True)\n",
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexage_df['renumber'] = \"sub-\" + sexage_df['renumber'] +\"_\" + sexage_df['TP'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stitched.merge(sexage_df, on=\"renumber\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# just in case there are duplicates in there\n",
    "result = result.loc[:,~result.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# confirm to standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standard_path = '../researcher_interface/sample_sep_values/showable_standard.csv'\n",
    "standard = pd.read_csv(standard_path)\n",
    "set_standard = set(standard.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = result.columns.str.lower()\n",
    "set_results= set(result.columns.to_list())\n",
    "\n",
    "z = set_results.intersection(set_standard) \n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in result.columns:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "## because in this case everything was session # 1 , run # 1 , we can just hard code that into the participant ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shift column 'Name' to first position\n",
    "first_column = result.pop('participant_id')\n",
    "  \n",
    "# insert column using insert(position,column_name,\n",
    "# first_column) function\n",
    "result.insert(0, 'participant_id', first_column)\n",
    "result['participant_id'] = result['participant_id']+'_ses-1_run-1'\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['session_id'] = result['session']\n",
    "second_column = result.pop('session_id')\n",
    "result.insert(1, 'session_id', second_column)\n",
    "result['site'] = \"SABRE\"\n",
    "result['run_id'] = result['longitudinaltimepoint']\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['gm_icv_ratio'] = result['gm_icvratio']\n",
    "result['gmwm_icv_ratio'] = result['gmwm_icvratio']\n",
    "result['cbf_gm_pvc0'] = 'NaN' \n",
    "result['cbf_gm_pvc2']=  result['totalgm_b'] \n",
    "result['cbf_wm_pvc0']= 'NaN'\n",
    "result['cbf_wm_pvc2']= result['deepwm_b']\n",
    "result['cbf_aca_pvc0'] =  'NaN'\n",
    "result['cbf_mca_pvc0']  = 'NaN'\n",
    "result['cbf_pca_pvc0'] =  'NaN'\n",
    "result['cbf_aca_pvc2']  = result['aca_b']\n",
    "result['cbf_mca_pvc2']  = result['mca_b']\n",
    "result['cbf_pca_pvc2']  = result['pca_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "result['cov_gm_pvc0'] =  'NaN' # corrected exist, but later\n",
    "# result['cov_gm_pvc2']  = result[]\n",
    "result['cov_wm_pvc0']  = 'NaN' # doesexist\n",
    "# result['cov_wm_pvc2']  = result[]\n",
    "result['cov_aca_pvc0'] =  'NaN'# does exist\n",
    "result['cov_mca_pvc0']  = 'NaN'# does exist\n",
    "result['cov_pca_pvc0']  = 'NaN'# does exist\n",
    "result['cov_aca_pvc2'] = result['aca_b_cov']\n",
    "result['cov_mca_pvc2'] = result['mca_b_cov']\n",
    "result['cov_pca_pvc2'] = result['pca_b_cov']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for f in result.columns:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['age'] = result['id.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sex_mapping = {2:'F',1:'M',}\n",
    "results = result.assign(sex = result.sex.map(sex_mapping))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shift columns to  position\n",
    "third_column = results.pop('run_id')\n",
    "fourth_column = results.pop('age')\n",
    "fifth_column = results.pop('sex')\n",
    "sixth_column = results.pop('site')\n",
    "seventh_column = results.pop('gm_vol')\n",
    "eight_column = results.pop('wm_vol')\n",
    "ninth_column = results.pop('csf_vol')\n",
    "tenth_column = results.pop('gm_icv_ratio')\n",
    "eleventh_column = results.pop('gmwm_icv_ratio')\n",
    "twelvth_column = results.pop('wmh_vol')\n",
    "thirteenth_column = results.pop('wmh_count')\n",
    "\n",
    "#last_column = results.pop('index')\n",
    "\n",
    "results.insert(2, 'run_id', third_column)\n",
    "results.insert(3, 'age', fourth_column)\n",
    "results.insert(4, 'sex', fifth_column)\n",
    "results.insert(5, 'site', sixth_column)\n",
    "results.insert(6, 'gm_vol', seventh_column)\n",
    "results.insert(7, 'wm_vol', eight_column)\n",
    "results.insert(8, 'csf_vol', ninth_column)\n",
    "results.insert(9, 'gm_ivc_ratio',tenth_column)\n",
    "results.insert(10, 'gmwm_ivc_ratio',eleventh_column)\n",
    "results.insert(11, 'wmh_vol',twelvth_column)\n",
    "results.insert(12, 'wmh_count',thirteenth_column)\n",
    "#results.insert(82, 'index', last_column)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = results.drop(['subjectnlist','id.1','renumber','session','longitudinaltimepoint', 'tp','gmwm_icvratio','gm_icvratio'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "standard.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reorg results to format\n",
    "head_columns = results.columns[:13]\n",
    "middle_columns = results.columns[13:43]\n",
    "tail_columns = results.columns[43:]\n",
    "f_results = pd.concat([results[head_columns],results[tail_columns],results[middle_columns]], axis=1)\n",
    "f_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in f_results.columns[6:]:\n",
    "    #print(column)\n",
    "    f_results[column] = pd.to_numeric(f_results[column], errors = 'coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep.check_sex_dimorph_expectations(f_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sep.relate_columns_graphs_numeric(f_results, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "# So somewhere in there there are negative numbers...this should not exist...\n",
    "let's find how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# So some of the soefficient of variations are negative. Is this really possible?\n",
    "\n",
    "Must be discussed with scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doubled_outliers =sep.find_outliers_by_list(f_results, f_results.columns.to_list()[6:], 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doubled_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../open_work/internal_results' \n",
    "filename = os.path.join(filepath,'possible_outliers_from_SABRE.csv') \n",
    "if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "    os.makedirs(filepath)\n",
    "doubled_outliers.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "save final file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filepath = '../open_work/internal_results' \n",
    "# filename = os.path.join(filepath,'SABRE_pvc2_stitched_conformed.csv') \n",
    "# if not os.path.exists(filepath):\n",
    "#     # if filder doesn't exist, create it\n",
    "#     os.makedirs(filepath)\n",
    "# f_results.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make clean version\n",
    "numeric_columns = ['age', 'gm_vol', 'wm_vol', 'csf_vol', 'gm_ivc_ratio', 'gmwm_ivc_ratio',\n",
    "       'wmh_vol', 'wmh_count', 'totalgm_l_cov', 'totalgm_r_cov', 'cbf_gm_pvc0',\n",
    "       'cbf_gm_pvc2', 'cbf_wm_pvc0', 'cbf_wm_pvc2', 'cbf_aca_pvc0',\n",
    "       'cbf_mca_pvc0', 'cbf_pca_pvc0', 'cbf_aca_pvc2', 'cbf_mca_pvc2',\n",
    "       'cbf_pca_pvc2', 'cov_gm_pvc0', 'cov_wm_pvc0', 'cov_aca_pvc0',\n",
    "       'cov_mca_pvc0', 'cov_pca_pvc0', 'cov_aca_pvc2', 'cov_mca_pvc2',\n",
    "       'cov_pca_pvc2', 'meanmotion', 'deepwm_b', 'deepwm_l', 'deepwm_r',\n",
    "       'aca_b', 'aca_l', 'aca_r', 'mca_b', 'mca_l', 'mca_r', 'pca_b', 'pca_l',\n",
    "       'pca_r', 'totalgm_b', 'totalgm_l', 'totalgm_r', 'mean_motion',\n",
    "       'deepwm_b_cov', 'deepwm_l_cov', 'deepwm_r_cov', 'aca_b_cov',\n",
    "       'aca_l_cov', 'aca_r_cov', 'mca_b_cov', 'mca_l_cov', 'mca_r_cov',\n",
    "       'pca_b_cov', 'pca_l_cov', 'pca_r_cov', 'totalgm_b_cov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_results = f_results[f_results['totalgm_b_cov'] > 0]\n",
    "#f_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results = f_results[f_results[\"aca_r_cov\"] > 0]\n",
    "f_results = f_results[f_results[\"mca_r_cov\"] > 0]\n",
    "f_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../open_work/internal_results/cleaned_pvc2s' \n",
    "filename = os.path.join(filepath,'SABRE_pvc2_cleaned.csv') \n",
    "if not os.path.exists(filepath):\n",
    "    # if filder doesn't exist, create it\n",
    "    os.makedirs(filepath)\n",
    "f_results.to_csv(filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_results[['gm_ivc_ratio','gmwm_ivc_ratio' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
