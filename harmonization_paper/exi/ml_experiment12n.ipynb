{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ML testing: experiment #12\n",
    "\n",
    "This notebook involves testing for the MRI conference abstract. This notebook shows mixed_dataset (TOP + StrokeMRI) based models once harmonized with open nested combat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # demo stuff\n",
    "# import ipywidgets as widgets\n",
    "# import seaborn \n",
    "\n",
    "# ml stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath_mri = '../open_work/internal_results/harmonized_pvc2s/' \n",
    "filename_mri = os.path.join(filepath_mri,'mri_opn_harmonized.csv') \n",
    "\n",
    "filepath_top = '../open_work/internal_results/harmonized_pvc2s/' \n",
    "filename_top = os.path.join(filepath_top,'top_opn_harmonized.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = pd.read_csv(filename_top)\n",
    "StrokeMRI = pd.read_csv(filename_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = TOP.drop(TOP.columns[0],axis=1)\n",
    "#TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI = StrokeMRI.drop(StrokeMRI.columns[0],axis=1)\n",
    "#StrokeMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for any duplicated patients\n",
    "strokers = set(StrokeMRI.participant_id)\n",
    "topers = set(TOP.participant_id)\n",
    "z = strokers.intersection(topers)\n",
    "print(z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make mixed dataset\n",
    "mixed_data = pd.concat([TOP, StrokeMRI], sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Build ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# keeping patient ID until right when model is fed, then use patient ID as key to what went where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_matrix = mixed_data #.drop('participant_id', axis=1)\n",
    "X = ml_matrix.drop('age', axis =1)\n",
    "X = X.values\n",
    "y = ml_matrix['age'].values\n",
    "y=y.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_cut = X_train[:,1:]\n",
    "X_train_cut = X_train_cut.astype('float')\n",
    "X_train_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_cut = X_test[:,1:]\n",
    "X_test_cut = X_test_cut.astype('float')\n",
    "X_test_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# svr_poly = SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=2, epsilon=0.1, coef0=1)\n",
    "# svr_poly.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = svr_poly.predict(X_test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('R2 score SV polynomial regression: %.3f' % svr_poly.score(X_test_cut,y_test))\n",
    "# print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "# print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "regr = MLPRegressor(random_state=1, max_iter=700)\n",
    "regr.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score neural network mlp regression: %.3f' % regr.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linr = LinearRegression()\n",
    "linr.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = linr.predict(X_test_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llreg = linear_model.LassoLars(alpha=0.01)\n",
    "llreg.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = llreg.predict(X_test_cut)\n",
    "print('R2 score Lasso regression: %.3f' % llreg.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeRegressor()\n",
    "dtree.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(X_test_cut)\n",
    "print('R2 score dtree regression: %.3f' % dtree.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svr_p2 = SVR(C=1.0, kernel='poly', degree =2, epsilon=0.2)\n",
    "svr_p2.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svr_p2.predict(X_test_cut)\n",
    "print('R2 score SVR 2nd degree poly kernel regression: %.3f' % svr_p2.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eregr = ElasticNetCV(cv=5, random_state=12)\n",
    "eregr.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = eregr.predict(X_test_cut)\n",
    "print('R2 score elasticnetcv regression: %.3f' % eregr.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etreg = ExtraTreesRegressor(n_estimators=100, random_state=0)\n",
    "etreg.fit(X_train_cut, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = etreg.predict(X_test_cut)\n",
    "print('R2 score extra trees regression: %.3f' % etreg.score(X_test_cut,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Save off models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if model folder exists and if not , then create\n",
    "model_folder = '../result_models/'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# joblib.dump(linr, ('../result_models/'+  'opn_harm_mixed_linr.sav'))\n",
    "# joblib.dump(llreg, ('../result_models/'+ 'opn_harm_mixed_lassor.sav'))\n",
    "# joblib.dump(dtree, ('../result_models/'+ 'opn_harm_mixed_dtree.sav'))\n",
    "# joblib.dump(regr, ('../result_models/'+  'opn_harm_mixed_regr.sav'))\n",
    "# joblib.dump(svr_p2, ('../result_models/'+'opn_harm_mixed_svrp2.sav'))\n",
    "# joblib.dump(eregr, ('../result_models/'+ 'opn_harm_mixed_elasticnet.sav'))\n",
    "# joblib.dump(etreg, ('../result_models/'+ 'opn_harm_mixed_extratree.sav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## Run models on other datasets (TOP, StrokeMRI)\n",
    "but without re-running the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# # Here we check tht no rows once patient IDs were pulled \n",
    "(if not we can map them back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_pandas = pd.DataFrame(X_train)\n",
    "X_train_pandas.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "tags": []
   },
   "source": [
    "top_ml_matrix\n",
    "needs to be mapped to top rows in X_train,\n",
    "we will use ese MD5 hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "now we need to make a dataframe of TOP minus what is in X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_pandas.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_train_pandas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_subjects = set(X_train_pandas[0])\n",
    "#trained_subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_subjects = set(TOP.participant_id)\n",
    "#TOP_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take trained subjects out of top subjects\n",
    "# we can use set math here\n",
    "new_top=(trained_subjects^TOP_subjects)&TOP_subjects\n",
    "print(len(new_top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "filter down to only top where they are in new_top set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP_new = TOP[TOP['participant_id'].isin(list(new_top))]\n",
    "TOP_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_ml_matrix = TOP_new.drop('participant_id', axis=1) \n",
    "X_top = top_ml_matrix.drop('age', axis =1)\n",
    "X_top = X_top.values\n",
    "X_top = X_top.astype('float')\n",
    "y_top = top_ml_matrix['age'].values\n",
    "y_top=y_top.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_top_test = X_top\n",
    "y_top_test = y_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = linr.predict(X_top_test)\n",
    "print('R2 score Linear regression: %.3f' % linr.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_top_pred = llreg.predict(X_top_test)\n",
    "print('R2 score Lasso linear regression: %.3f' % llreg.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = dtree.predict(X_top_test)\n",
    "print('R2 score decision tree regression: %.3f' % dtree.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = regr.predict(X_top_test)\n",
    "print('R2 score MLP regression: %.3f' % regr.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = svr_p2.predict(X_top_test)\n",
    "print('R2 score SVR poly 2 regression: %.3f' % svr_p2.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = eregr.predict(X_top_test)\n",
    "print('R2 score ElasticnetCV regression: %.3f' % eregr.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_top_pred = etreg.predict(X_top_test)\n",
    "print('R2 score Extra treen: %.3f' % etreg.score(X_top_test,y_top_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_top_test, y_top_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_top_test, y_top_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI_subjects = set(StrokeMRI.participant_id)\n",
    "#StrokeMRI_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take trained subjects out of top subjects\n",
    "# we can use set math here\n",
    "\n",
    "new_mri=(trained_subjects^StrokeMRI_subjects)&StrokeMRI_subjects\n",
    "print(len(new_mri))\n",
    "#print(new_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI_new = StrokeMRI[StrokeMRI['participant_id'].isin(list(new_mri))]\n",
    "StrokeMRI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strokemri_ml_matrix = StrokeMRI_new.drop('participant_id', axis=1) \n",
    "\n",
    "X_mri = strokemri_ml_matrix.drop('age', axis =1)\n",
    "X_mri = X_mri.values\n",
    "X_mri = X_mri.astype('float')\n",
    "y_mri = strokemri_ml_matrix['age'].values\n",
    "y_mri=y_mri.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mri_test = X_mri\n",
    "y_mri_test = y_mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = linr.predict(X_mri_test)\n",
    "print('R2 score Linear regression: %.3f' % linr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = llreg.predict(X_mri_test)\n",
    "print('R2 score Lasso-linear regression: %.3f' % llreg.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = dtree.predict(X_mri_test)\n",
    "print('R2 score decision tree regression: %.3f' % dtree.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = regr.predict(X_mri_test)\n",
    "print('R2 score MLP regression: %.3f' % regr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mri_pred = svr_p2.predict(X_mri_test)\n",
    "print('R2 score SVR poly2 regression: %.3f' % svr_p2.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mri_pred = eregr.predict(X_mri_test)\n",
    "print('R2 score Ekasticnet CV: %.3f' % eregr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = etreg.predict(X_mri_test)\n",
    "print('R2 score Extra tree regression: %.3f' % etreg.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
