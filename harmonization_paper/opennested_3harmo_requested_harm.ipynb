{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Open nested combat: TOP plus StrokeMRI, SABRE and Insight46,  open nested-harmonized datasets,\n",
    "##  SABRE and Insight46, each as it's own batch\n",
    "## TOP plus StrokeMRI treated as a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Note this must be run in the `opnc` environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import permutations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import neuroCombat as nC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import ranksums, ttest_ind, ttest_rel, ks_2samp, anderson_ksamp\n",
    "\n",
    "sys.path.insert(0, '../') # path to cvasl functions\n",
    "import cvasl.seperated as sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Read in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "filename_mri = os.path.join(filepath,'StrokeMRI_pvc2c.csv') \n",
    "filename_top = os.path.join(filepath,'TOP_pvc2c.csv') \n",
    "filename_sabre = os.path.join(filepath,'SABRE_pvc2_cleaned.csv') \n",
    "filename_insight = os.path.join(filepath,'Insight46_pvc2c.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = pd.read_csv(filename_mri)\n",
    "top = pd.read_csv(filename_top)\n",
    "sabre = pd.read_csv(filename_sabre)\n",
    "insight = pd.read_csv(filename_insight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up sabre to be like others\n",
    "coly = top.columns\n",
    "sabre = sabre[coly]\n",
    "sabre = sabre.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabre.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insight.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now we make a blended set of mri and top \n",
    "topmri = pd.concat([top, mri])\n",
    "topmri.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Below are functions out of the Hannah Horng Opn-combat library\n",
    "The library is here https://github.com/hannah-horng/opnested-combat\n",
    "As the library is unreleased and unversioned, we are using the MIT lisenced functions directly to version control them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from opncombat\n",
    "def OPNestedComBat(dat, covars, batch_list, filepath, categorical_cols=None, continuous_cols=None, return_estimates=False):\n",
    "    \"\"\"\n",
    "    Completes sequential OPNested ComBat harmonization on an input DataFrame. Order is determined by running through all\n",
    "    possible permutations of the order, then picking the order with the lowest number of features with significant\n",
    "    differences in distribution.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (features, samples)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "        encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : root directory path for saving KS test p-values and kernel density plots created during harmonization\n",
    "    categorical_cols : string or list of strings of categorical variables to adjust for\n",
    "    continuous_cols : string or list of strings of continuous variables to adjust for\n",
    "    return_estimates : if True, function will return both output_df and final_estimates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_df : DataFrame with shape (features, samples) that has been sequentially harmonized with Nested ComBat\n",
    "    final_estimates : list of dictionaries of estimates from iterative harmonization, used if user is deriving estimates\n",
    "        from training data that need to be applied to a separate validation dataset\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    perm_list = list(permutations(np.arange(len(batch_list))))\n",
    "    count_dict = {}\n",
    "    feature_dict = {}\n",
    "    estimate_dict = {}\n",
    "    c = 0\n",
    "    for order in perm_list:\n",
    "        c += 1\n",
    "        n_dat = dat.copy()\n",
    "        estimate_list = []\n",
    "        print('Iteration ' + str(c) + ' of ' + str(len(perm_list)))\n",
    "        for i in order:\n",
    "            batch_col = batch_list[i]\n",
    "            output = nC.neuroCombat(n_dat, covars, batch_col, continuous_cols=continuous_cols,\n",
    "                                    categorical_cols=categorical_cols)\n",
    "            output_df = pd.DataFrame.from_records(output['data'].T)\n",
    "            n_dat = output_df.T\n",
    "            estimate_list.append(output['estimates'])\n",
    "        output_df.columns = dat.index\n",
    "        feature_dict[str(order)] = n_dat\n",
    "        count_dict[str(order)] = 0\n",
    "        estimate_dict[str(order)] = estimate_list\n",
    "        for batch_col in batch_list:\n",
    "            p_list = []\n",
    "            # print(batch_col)\n",
    "            for j in range(len(output_df.columns)):\n",
    "                feature = output_df.iloc[:, j]\n",
    "                # print(j)\n",
    "                split_col = [feature[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list.append(anderson_ksamp(split_col).significance_level)\n",
    "            count_dict[str(order)] += np.sum(np.asarray(p_list) < 0.05)\n",
    "    if len(batch_list) != 1:\n",
    "        best_order = [key for key, value in count_dict.items() if value == min(count_dict.values())][0]\n",
    "        best_order_list = list(map(int, best_order[1:-1].split(', ')))\n",
    "        order = [batch_list[i] for i in best_order_list]\n",
    "        n_dat = feature_dict[best_order]\n",
    "        final_estimate = estimate_dict[best_order] \n",
    "\n",
    "    print('Final Order: ' + str(order))\n",
    "\n",
    "    txt_path = filepath + 'order.txt'\n",
    "    with open(txt_path, 'w') as f:\n",
    "        for item in order:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    output_df = pd.DataFrame.from_records(n_dat.T)\n",
    "    output_df.columns = dat.index\n",
    "    if return_estimates:\n",
    "        return output_df, final_estimate\n",
    "    else:\n",
    "        return output_df\n",
    "\n",
    "\n",
    "def feature_ad(dat, output_df, covars, batch_list, filepath):\n",
    "    \"\"\"\n",
    "    Computes AD test p-values separated by batch effect groups for a dataset (intended to assess differences in\n",
    "    distribution to all batch effects in batch_list following harmonization NestedComBat\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (samples, features)\n",
    "    output_df: DataFrame of harmonized data with shape (samples, features)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "            encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : write destination for kernel density plots and p-values\n",
    "\n",
    "    If a feature is all the same value, the AD test cannot be completed.\n",
    "\n",
    "    \"\"\"\n",
    "    p_df_original = pd.DataFrame()\n",
    "    p_df_combat = pd.DataFrame()\n",
    "    for batch_col in batch_list:\n",
    "\n",
    "        # Computing KS Test P-Values\n",
    "        p_list_original = []\n",
    "        p_list_combat = []\n",
    "        for j in range(len(output_df.columns)):\n",
    "            feature_original = dat.iloc[:, j]\n",
    "            feature_combat = output_df.iloc[:, j]\n",
    "            try:\n",
    "                split_col_original = [feature_original[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list_original.append(anderson_ksamp(split_col_original).significance_level)\n",
    "                split_col_combat = [feature_combat[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list_combat.append(anderson_ksamp(split_col_combat).significance_level)\n",
    "            except ValueError:\n",
    "                print('Feature is all same value: ' + output_df.columns[j])\n",
    "\n",
    "        p_df_original[batch_col] = p_list_original\n",
    "        p_df_combat[batch_col] = p_list_combat\n",
    "\n",
    "    p_df_original.index = dat.columns\n",
    "    p_df_combat.index = output_df.columns\n",
    "    p_df_original.to_csv(filepath + 'p_values_original.csv')\n",
    "    p_df_combat.to_csv(filepath + 'p_values_combat.csv')\n",
    "    \n",
    "\n",
    "def feature_histograms(dat, output_df, covars, batch_list, filepath):\n",
    "    \"\"\"\n",
    "    Plots kernel density plots and computes KS test p-values separated by batch effect groups for a dataset (intended\n",
    "    to assess differences in distribution to all batch effects in batch_list following harmonization with\n",
    "    NestedComBat\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (samples, features)\n",
    "    output_df: DataFrame of harmonized data with shape (samples, features)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "        encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : write destination for kernel density plots and p-values\n",
    "    ad : KS test for binary batch effects if False, Anderson-Darling test for categorical batch effects if True\n",
    "\n",
    "    \"\"\"\n",
    "    for batch_col in batch_list:\n",
    "        filepath3 = filepath + batch_col + '/'\n",
    "        if not os.path.exists(filepath3):\n",
    "            os.makedirs(filepath3)\n",
    "\n",
    "        # Plotting Kernel Density Plots\n",
    "        for col in output_df:\n",
    "            feature_original = dat[col]\n",
    "            feature_combat = output_df[col]\n",
    "\n",
    "            try:\n",
    "\n",
    "                plt.figure()\n",
    "                for i in covars[batch_col].unique():\n",
    "                    feature_original[covars[batch_col] == i].plot.kde(color='r', alpha=0.75)\n",
    "                for i in covars[batch_col].unique():\n",
    "                    feature_combat[covars[batch_col] == i].plot.kde(color='b', alpha=0.5)\n",
    "                    if max(feature_combat[covars[batch_col] == i]) > 1:\n",
    "                        plt.xlim([0, 200])\n",
    "                plt.xlabel(col)\n",
    "                plt.ylabel('Density')\n",
    "                leg = ['Original', 'ComBat']\n",
    "                plt.legend(leg)\n",
    "                ax = plt.gca()\n",
    "                leg = ax.get_legend()\n",
    "                leg.legendHandles[0].set_color('r')\n",
    "                leg.legendHandles[1].set_color('b')\n",
    "\n",
    "                filename = filepath3 + 'histogram_' + col + \".png\"\n",
    "                plt.savefig(filename, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                plt.close('all')\n",
    "            except np.linalg.linalg.LinAlgError:\n",
    "                print('Failed to plot: ' + col)\n",
    "\n",
    "\n",
    "def GMMSplit(dat, caseno, filepath):\n",
    "    \"\"\"\n",
    "    Completes Gaussian Mixture model fitting and ComBat harmonization by the resulting sample grouping. The assumption\n",
    "    here is that there is an unknown batch effect causing bimodality such that we can estimate the sample groupings for\n",
    "    this hidden batch effect from the distribution. This function will take in a dataset, determine the best 2-component\n",
    "    Gaussian mixture model, and use the resulting sample grouping to harmonize the data with ComBat.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (features, samples)\n",
    "    caseno : DataFrame/Series containing sample IDs (should be aligned with dat and covars), used to return sample\n",
    "        grouping assignments.\n",
    "    filepath : root directory path for saving the grouping and corresponding kernel density plots\n",
    "    -------\n",
    "    new_dat : DataFrame with shape (features, samples) that has been sequentially harmonized with Nested ComBat\n",
    "\n",
    "    \"\"\"\n",
    "    # GENERATING GMM GROUPING\n",
    "    data_keys = list(dat.T.keys())\n",
    "    aic_values = []\n",
    "    predictions = []\n",
    "    col_list = []\n",
    "    final_keys = []\n",
    "    filepath2 = filepath+'GMM_Split/'\n",
    "    if not os.path.exists(filepath2):\n",
    "        os.makedirs(filepath2)\n",
    "\n",
    "    for i in range(len(data_keys)):\n",
    "        # print(col)\n",
    "        feature = dat.T.iloc[:, i]\n",
    "        X = pd.DataFrame({0: feature, 1: feature})\n",
    "        gmix = GaussianMixture(n_components=2)\n",
    "        col = data_keys[i]\n",
    "        try:\n",
    "            gmix.fit(X)\n",
    "            results = gmix.predict(X)\n",
    "            cluster_0 = X[results == 0].iloc[:, 0]\n",
    "            cluster_1 = X[results == 1].iloc[:, 0]\n",
    "            # print(len(cluster_0))\n",
    "            if len(cluster_0) <= .25*len(caseno) or len(cluster_1) <= .25*len(caseno):\n",
    "                print('Clusters unbalanced: ' + data_keys[i])\n",
    "            else:\n",
    "                try:\n",
    "                    plt.figure()\n",
    "                    cluster_0.plot.kde()\n",
    "                    cluster_1.plot.kde()\n",
    "                    X.iloc[:, 0].plot.kde()\n",
    "                    plt.legend(['Cluster 0', 'Cluster 1', 'Original'])\n",
    "                    plt.xlabel(data_keys[i])\n",
    "                    filename = filepath2 + 'histogram_' + data_keys[i] + \".png\"\n",
    "                    plt.savefig(filename, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                except:\n",
    "                    plt.close()\n",
    "                    print('Failed to plot: ' + col)\n",
    "                final_keys.append(col)\n",
    "                predictions.append(results)\n",
    "                aic_values.append(gmix.aic(X))\n",
    "                col_list.append(col)\n",
    "        except ValueError:\n",
    "            print('Failed to fit: ' + col)\n",
    "            # aic_values.append(np.nan)\n",
    "\n",
    "    # Returning AIC values\n",
    "    gaussian_df = pd.DataFrame({'Feature': final_keys, 'AIC': aic_values})\n",
    "    best_fit = gaussian_df[gaussian_df['AIC'] == min(gaussian_df['AIC'])]['Feature'].iloc[0].strip(' ')\n",
    "    best_fit_n = gaussian_df[gaussian_df['AIC'] == min(gaussian_df['AIC'])]['Feature'].index[0]\n",
    "    gaussian_df.to_csv(filepath2 + 'GaussianMixture_aic_values.csv')\n",
    "\n",
    "    # Returning patient split\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df['Patient'] = caseno\n",
    "    predictions_df['Grouping'] = predictions[best_fit_n]\n",
    "    predictions_df.to_csv(filepath2 + best_fit + '_split.csv')\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "topmri_batch_testing_df = topmri[['participant_id','age', 'sex']]\n",
    "topmri_batch_testing_df['site'] = 1\n",
    "column_to_move = topmri_batch_testing_df.pop(\"site\")\n",
    "topmri_batch_testing_df.insert(1, \"site\", column_to_move)\n",
    "#top_batch_testing_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('number of rows in topmri', len(topmri))\n",
    "print('number of rows in sabre', len(sabre))\n",
    "print('number of rows in insight', len(insight))\n",
    "print('number of rows in all', len(topmri) +len(sabre) + len(insight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_batch_testing_df = insight[['participant_id','age', 'sex']]\n",
    "insight_batch_testing_df['site'] = 2\n",
    "column_to_move = insight_batch_testing_df.pop(\"site\")\n",
    "insight_batch_testing_df.insert(1, \"site\", column_to_move)\n",
    "#insight_batch_testing_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insight_batch_testing_df ## note insight adds 282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabre_batch_testing_df = sabre[['participant_id','age', 'sex']]\n",
    "sabre_batch_testing_df['site'] = 3\n",
    "column_to_move = sabre_batch_testing_df.pop(\"site\")\n",
    "sabre_batch_testing_df.insert(1, \"site\", column_to_move)\n",
    "#sabre_batch_testing_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_testing_df = pd.concat(\n",
    "    [topmri_batch_testing_df, insight_batch_testing_df, sabre_batch_testing_df],\n",
    "    ignore_index=True)\n",
    "batch_testing_df = sep.recode_sex_to_numeric(batch_testing_df)\n",
    "#batch_testing_df.tail(5)\n",
    "len(batch_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in batch effects\n",
    "batch_testing_list = ['site']\n",
    "# Loading in clinical covariates\n",
    "categorical_testing_cols = ['sex']\n",
    "continuous_testing_cols = ['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASL\n",
    "data_testing_df = pd.concat([topmri,insight,sabre])\n",
    "#data_testing_df = # ASL\n",
    "data_testing_df = data_testing_df.drop(columns=['Unnamed: 0','age','sex'])  \n",
    "data_testing_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_testing_df = data_testing_df.reset_index(drop=True)\n",
    "data_testing_df = data_testing_df.dropna()\n",
    "data_testing_df = data_testing_df.merge(batch_testing_df['participant_id'], \n",
    "                                        left_on='participant_id', right_on='participant_id')\n",
    "dat_testing = data_testing_df.iloc[:, 1:]\n",
    "dat_testing = dat_testing.T.apply(pd.to_numeric)\n",
    "caseno_testing = data_testing_df['participant_id']\n",
    "covars_testing = batch_testing_df.drop('participant_id',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging batch effects, clinical covariates\n",
    "covars_testing_string = pd.DataFrame()\n",
    "covars_testing_string[categorical_testing_cols] = covars_testing[categorical_testing_cols].copy()\n",
    "covars_testing_quant = covars_testing[continuous_testing_cols]\n",
    "#covars_testing_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "covars_testing_cat = pd.DataFrame()\n",
    "for col_testing in covars_testing_string:\n",
    "    stringcol_testing = covars_testing_string[col_testing]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(stringcol_testing))\n",
    "    covars_testing_cat[col_testing] = le.transform(stringcol_testing)\n",
    "#covars_testing_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "covars_testing_final = pd.concat([covars_testing_cat, covars_testing_quant], axis=1)\n",
    "#covars_testing_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # FOR GMM COMBAT VARIANTS:\n",
    "# # # Adding GMM Split to batch effects\n",
    "filepath2 = 'Testing/OPPNComBat/ResultTesting'\n",
    "if not os.path.exists(filepath2):\n",
    "    os.makedirs(filepath2)\n",
    "gmm_testing_df = GMMSplit(dat_testing, caseno_testing, filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_testing_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_testing_df_merge = batch_testing_df.merge(gmm_testing_df, right_on='Patient', left_on='participant_id')\n",
    "gmm_testing_df_merge['GMM'] = gmm_testing_df_merge['Grouping'] \n",
    "gmm_testing_df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "covars_testing_final = gmm_testing_df_merge.drop(['participant_id','Patient','Grouping'],1)\n",
    "categorical_testing_cols = categorical_testing_cols + ['GMM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_testing_df = OPNestedComBat(dat_testing,\n",
    "                                   covars_testing_final,\n",
    "                                   batch_testing_list,\n",
    "                                   filepath2, categorical_cols=categorical_testing_cols,\n",
    "                                  continuous_cols=continuous_testing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the AD test p-values to measure harmonziation performance\n",
    "feature_ad(dat_testing.T, output_testing_df, covars_testing_final, batch_testing_list, filepath2)\n",
    "# plot kernel density plots to visualize distributions before and after harmonization\n",
    "feature_histograms(dat_testing.T, output_testing_df, covars_testing_final, batch_testing_list, filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_testing_df = pd.concat([caseno_testing, output_testing_df], axis=1) \n",
    "write_testing_df.to_csv(filepath2+'/Mfeatures_testing_NestedComBat.csv') # write results fo file\n",
    "dat_testing_input = dat_testing.transpose()\n",
    "dat_testing_input.to_csv(filepath2+'/Mfeatures_input_testing_NestedComBat.csv')\n",
    "covars_testing_final.to_csv(filepath2+'/Mcovars_input_testing_NestedComBat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write harmonized dataset \n",
    "complete_harmonised = pd.concat([write_testing_df, covars_testing_final], axis=1) \n",
    "complete_harmonised.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_harmonised['site'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(complete_harmonised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# split dataframe back up into parts for running\n",
    "## from complete_harmonised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_opn_harmonized = complete_harmonised[complete_harmonised['site'] == 2]\n",
    "insight_opn_harmonized = insight_opn_harmonized.drop(columns=['site', 'GMM',])\n",
    "insight_opn_harmonized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "topmri_opn_harmonized = complete_harmonised[complete_harmonised['site'] == 1]\n",
    "topmri_opn_harmonized = topmri_opn_harmonized.drop(columns=['site', 'GMM',])\n",
    "#topmri_opn_harmonized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sabre_opn_harmonized = complete_harmonised[complete_harmonised['site'] == 3]\n",
    "sabre_opn_harmonized = sabre_opn_harmonized.drop(columns=['site', 'GMM',])\n",
    "#top_opn_harmonized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "topmri_opn_harmonized.to_csv('Rtopmri_opn_harmonized.csv')\n",
    "insight_opn_harmonized.to_csv('Rinsight_opn_harmonized.csv')\n",
    "sabre_opn_harmonized.to_csv('Rsabre_opn_harmonized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insight_opn_harmonized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Make mixed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_selection = insight.drop(['Unnamed: 0'],axis=1)\n",
    "topmri_selection = topmri.drop(['Unnamed: 0'],axis=1)\n",
    "sab_selection = sabre.drop(['Unnamed: 0'],axis=1)\n",
    "    \n",
    "insight_selection = insight_selection.set_index('participant_id')\n",
    "topmri_selection = topmri_selection.set_index('participant_id')\n",
    "sab_selection = sab_selection.set_index('participant_id')\n",
    "#sab_selection.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\n",
    "    'age': 'age_unharm', # will be the key on merge\n",
    "    'sex':'sex_unharm',\n",
    "    'gm_vol' :'gm_vol_unharm',\n",
    "    'wm_vol' :'wm_vol_unharm',\n",
    "    'csf_vol':'csf_vol_unharm',\n",
    "    'gm_ivc_ratio': 'gm_ivc_ratio_unharm',\n",
    "    'gmwm_ivc_ratio': 'gmwm_ivc_ratio_unharm',\n",
    "    'wmh_vol' :'wmh_vol_unharm',\n",
    "    'wmh_count' : 'wmh_count_unharm',\n",
    "    'deepwm_b_cov':'deepwm_b_cov_unharm',\n",
    "    'aca_b_cov': 'aca_b_cov_unharm',\n",
    "    'mca_b_cov': 'mca_b_cov_unharm',\n",
    "    'pca_b_cov': 'pca_b_cov_unharm',\n",
    "    'totalgm_b_cov':'totalgm_b_cov_unharm',\n",
    "    'deepwm_b':'deepwm_b_unharm',\n",
    "    'aca_b':'aca_b_unharm',\n",
    "    'mca_b':'mca_b_unharm',\n",
    "    'pca_b':'pca_b_unharm',\n",
    "    'totalgm_b':'totalgm_b_unharm', \n",
    "\n",
    "}\n",
    "insight_selection = insight_selection.rename(columns = rename_dict)\n",
    "topmri_selection = topmri_selection.rename(columns = rename_dict)\n",
    "sab_selection = sab_selection.rename(columns = rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_selection = insight_selection.reset_index()\n",
    "topmri_selection = topmri_selection.reset_index()\n",
    "sab_selection = sab_selection.reset_index()\n",
    "topmri_selection.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "topmri_opn_harmonized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_selection = insight_selection.merge(insight_opn_harmonized, how= 'inner',)\n",
    "topmri_selection = topmri_selection.merge(topmri_opn_harmonized,  how= 'inner',)\n",
    "sab_selection = sab_selection.merge(sabre_opn_harmonized, how= 'inner',)\n",
    "#topmri_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "insight_selection.to_csv('opn_harm3way_insight_before_after.csv')\n",
    "topmri_selection.to_csv('opn_harm3way_topmri_before_after.csv')\n",
    "sab_selection.to_csv('opn_harm3way_sabre_before_after.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation prep\n",
    "complete_harmonised['Harmonised'] = 'H'\n",
    "complete_nonharmonised = pd.concat([caseno_testing, dat_testing_input], axis=1) \n",
    "complete_nonharmonised = pd.concat([complete_nonharmonised, covars_testing_final], axis=1) \n",
    "complete_nonharmonised['Harmonised'] = 'UH'\n",
    "complete_harmonised_nonharmonised_merged = complete_harmonised.append(complete_nonharmonised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.nan\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['sex'] == 0) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'H'), 'H_Male', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['sex'] == 1) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'H'), 'H_Female', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['sex'] == 0) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'UH'), 'UH_Male', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['sex'] == 1) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'UH'), 'UH_Female', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonisation'] = complete_harmonised_nonharmonised_merged['Harmonised']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = widgets.Dropdown(\n",
    "    options=complete_harmonised_nonharmonised_merged.columns.tolist(),\n",
    "    value='gm_vol',\n",
    "    description='Feature',\n",
    "    disabled=False\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature =features.value\n",
    "y_axis = feature\n",
    "viz_data = complete_harmonised_nonharmonised_merged\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.catplot(data = complete_harmonised_nonharmonised_merged, x = 'Harmonisation', y = y_axis, hue =\"sex\", \n",
    "split=True, inner = 'quartile', kind = 'violin', \n",
    "col = 'site', height = 5, aspect = 0.6)\n",
    "plt.ylim((viz_data[y_axis].min(),viz_data[y_axis].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
