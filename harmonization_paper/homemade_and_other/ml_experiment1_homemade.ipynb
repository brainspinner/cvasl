{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ML testing: experiment #1- homemade harmonization\n",
    "\n",
    "This notebook involves testing for the MRI conference abstract. This notebook shows TOP based models with TOP having in this case been harmonized to the MRI dataset by polynomial displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import sys\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# demo stuff\n",
    "#import ipywidgets as widgets\n",
    "#import seaborn \n",
    "\n",
    "# ml stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.path.insert(0, '../') # path to functions\n",
    "import cvasl.seperated as sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath_mri = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "filename_mri = os.path.join(filepath_mri,'StrokeMRI_pvc2c.csv') \n",
    "\n",
    "#filepath_top = '../open_work/internal_results/cleaned_pvc2s/' \n",
    "filename_top = 'TOP_mri_homemade_harmonized.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = pd.read_csv(filename_top)\n",
    "StrokeMRI = pd.read_csv(filename_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOP = TOP.drop(TOP.columns[0],axis=1)\n",
    "#TOP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TOP = TOP.rename(columns={'totalgm_b.1':'totalgm_b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI = StrokeMRI.drop(StrokeMRI.columns[0],axis=1)\n",
    "#StrokeMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we need to flip the sex back to numbers for a correlation\n",
    "sex_mapping = {'F':0,'M':1}\n",
    "TOP = TOP.assign(sex = TOP.sex.map(sex_mapping))\n",
    "TOP.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "StrokeMRI = StrokeMRI.assign(sex = StrokeMRI.sex.map(sex_mapping))\n",
    "StrokeMRI.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Build ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_matrix = TOP.drop('participant_id', axis=1)\n",
    "X = ml_matrix.drop('age', axis =1)\n",
    "X = X.values\n",
    "X = X.astype('float')\n",
    "y = ml_matrix['age'].values\n",
    "y=y.astype('float')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linr = LinearRegression()\n",
    "linr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = linr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score Linear regression: %.3f' % linr.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'linear regression',\n",
    "    'unharm_top_linr.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    linr.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "linr_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "linr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llreg = linear_model.LassoLars(alpha=0.01)\n",
    "llreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = llreg.predict(X_test)\n",
    "print('R2 score Lasso regression: %.3f' % llreg.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'lasso linear regression',\n",
    "    'unharm_top_lassor.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    llreg.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "llreg_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "llreg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeRegressor()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(X_test)\n",
    "print('R2 score dtree regression: %.3f' % dtree.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'decision tree',\n",
    "    'unharm_top_dtree.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    dtree.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "dtree_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "dtree_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=900)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('R2 score neural network mlp regression: %.3f' % regr.score(X_test,y_test))\n",
    "# print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "# print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'MLP regression',\n",
    "    'unharm_top_regr.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    regr.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "regr_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "regr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svr_p2 = SVR(C=1.0, kernel='poly', degree =2, epsilon=0.2)\n",
    "svr_p2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svr_p2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('R2 score SVR 2nd degree poly kernel regression: %.3f' % svr_p2.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'SVR poly2',\n",
    "    'unharm_top_svrp2.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    svr_p2.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "svr_p2_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "svr_p2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eregr = ElasticNetCV(cv=5, random_state=12)\n",
    "eregr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = eregr.predict(X_test)\n",
    "print('R2 score elasticnetcv regression: %.3f' % eregr.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'Elastic_netCV',\n",
    "    'unharm_top_eregr.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    eregr.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "eregr_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "eregr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etreg = ExtraTreesRegressor(n_estimators=100, random_state=0)\n",
    "etreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = etreg.predict(X_test)\n",
    "print('R2 score extra trees regression: %.3f' % etreg.score(X_test,y_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_test, y_pred))\n",
    "print('MAE: % .3f' % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= [[\n",
    "    'Extra trees',\n",
    "    'unharm_top_etreg.sav',\n",
    "    mean_absolute_error(y_test, y_pred),\n",
    "    etreg.score(X_test,y_test),\n",
    "    metrics.explained_variance_score(y_test, y_pred)]]\n",
    "etreg_results = pd.DataFrame(data, columns=['algorithm','file_name','mae', 'r2', 'explained_variance'])\n",
    "etreg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_based_hm_harmonized_on_top =pd.concat([linr_results,\n",
    "                   llreg_results,\n",
    "                   dtree_results,\n",
    "                   regr_results,\n",
    "                   svr_p2_results,\n",
    "                   eregr_results,\n",
    "                  etreg_results],\n",
    "                  axis=0)\n",
    "top_based_hm_harmonized_on_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_based_hm_harmonized_on_top.to_csv('top_based_unharmonized_on_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAve off models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check if model folder exists and if not , then create\n",
    "model_folder = '../result_models/'\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# joblib.dump(linr, ('../result_models/'+  'homemade_harm1_top_linr.sav'))\n",
    "# joblib.dump(llreg, ('../result_models/'+ 'homemade_harm1_top_lassor.sav'))\n",
    "# joblib.dump(dtree, ('../result_models/'+ 'homemade_harm1_top_dtree.sav'))\n",
    "# joblib.dump(regr, ('../result_models/'+  'homemade_harm1_top_regr.sav'))\n",
    "# joblib.dump(svr_p2, ('../result_models/'+'homemade_harm1_top_svrp2.sav'))\n",
    "# joblib.dump(etreg, ('../result_models/'+ 'homemade_harm1_top_extratree.sav'))\n",
    "# joblib.dump(eregr, ('../result_models/'+ 'homemade_harm1_top_elasticregr.sav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Run models on other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mri_ml_matrix = StrokeMRI.drop('participant_id', axis=1)\n",
    "X_mri = mri_ml_matrix.drop('age', axis =1)\n",
    "X_mri = X_mri.values\n",
    "X_mri = X_mri.astype('float')\n",
    "y_mri = mri_ml_matrix['age'].values\n",
    "y_mri=y_mri.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_mri_test = X_mri\n",
    "y_mri_test = y_mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = linr.predict(X_mri_test)\n",
    "print('R2 score Linear regression: %.3f' % linr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = llreg.predict(X_mri_test)\n",
    "print('R2 score Lasso regression: %.3f' % llreg.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = dtree.predict(X_mri_test)\n",
    "print('R2 score Decision tree: %.3f' % dtree.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = regr.predict(X_mri_test)\n",
    "print('R2 score MLP regression: %.3f' % regr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = svr_p2.predict(X_mri_test)\n",
    "print('R2 score SVR polynomial regression: %.3f' % svr_p2.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = eregr.predict(X_mri_test)\n",
    "print('R2 score ElasticNet CV : %.3f' % eregr.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mri_pred = etreg.predict(X_mri_test)\n",
    "print('R2 score extra tree regression: %.3f' % etreg.score(X_mri_test,y_mri_test))\n",
    "print('Explained variance score: %.3f'  % metrics.explained_variance_score(y_mri_test, y_mri_pred))\n",
    "print('The mean absolute error: %.3f' % mean_absolute_error(y_mri_test, y_mri_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.scatter(y_test, y_pred, c='crimson')\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "\n",
    "# p1 = max(max(y_pred), max(y_test))\n",
    "# p2 = min(min(y_pred), min(y_test))\n",
    "# plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "# plt.xlabel('True Values', fontsize=15)\n",
    "# plt.ylabel('Predictions', fontsize=15)\n",
    "# plt.axis('equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
