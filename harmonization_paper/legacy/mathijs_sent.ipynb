{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e9c247-dacb-40c8-9774-42c7c12f1f0d",
   "metadata": {},
   "source": [
    "## Mathijs violin plot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccc0a8-3dc1-48d2-af83-08902b8df668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Written by Hannah Horng (hhorng@seas.upenn.edu)\n",
    "import pandas as pd\n",
    "import neuroCombat as nC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ranksums, ttest_ind, ttest_rel, ks_2samp, anderson_ksamp\n",
    "import os\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07585c09-c50b-4170-b06c-bfc6ba1812f8",
   "metadata": {},
   "source": [
    "## Below are functions out of the Hannah Horng Opn-combat library\n",
    "As the library is unreleased and unversioned, we are using the MIT lisenced functions directly to version control them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ce97b-c077-46d3-8bde-103e9ce2a2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions from opncombat\n",
    "def OPNestedComBat(dat, covars, batch_list, filepath, categorical_cols=None, continuous_cols=None, return_estimates=False):\n",
    "    \"\"\"\n",
    "    Completes sequential OPNested ComBat harmonization on an input DataFrame. Order is determined by running through all\n",
    "    possible permutations of the order, then picking the order with the lowest number of features with significant\n",
    "    differences in distribution.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (features, samples)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "        encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : root directory path for saving KS test p-values and kernel density plots created during harmonization\n",
    "    categorical_cols : string or list of strings of categorical variables to adjust for\n",
    "    continuous_cols : string or list of strings of continuous variables to adjust for\n",
    "    return_estimates : if True, function will return both output_df and final_estimates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_df : DataFrame with shape (features, samples) that has been sequentially harmonized with Nested ComBat\n",
    "    final_estimates : list of dictionaries of estimates from iterative harmonization, used if user is deriving estimates\n",
    "        from training data that need to be applied to a separate validation dataset\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    perm_list = list(permutations(np.arange(len(batch_list))))\n",
    "    count_dict = {}\n",
    "    feature_dict = {}\n",
    "    estimate_dict = {}\n",
    "    c = 0\n",
    "    for order in perm_list:\n",
    "        c += 1\n",
    "        n_dat = dat.copy()\n",
    "        estimate_list = []\n",
    "        print('Iteration ' + str(c) + ' of ' + str(len(perm_list)))\n",
    "        for i in order:\n",
    "            batch_col = batch_list[i]\n",
    "            output = nC.neuroCombat(n_dat, covars, batch_col, continuous_cols=continuous_cols,\n",
    "                                    categorical_cols=categorical_cols)\n",
    "            output_df = pd.DataFrame.from_records(output['data'].T)\n",
    "            n_dat = output_df.T\n",
    "            estimate_list.append(output['estimates'])\n",
    "        output_df.columns = dat.index\n",
    "        feature_dict[str(order)] = n_dat\n",
    "        count_dict[str(order)] = 0\n",
    "        estimate_dict[str(order)] = estimate_list\n",
    "        for batch_col in batch_list:\n",
    "            p_list = []\n",
    "            # print(batch_col)\n",
    "            for j in range(len(output_df.columns)):\n",
    "                feature = output_df.iloc[:, j]\n",
    "                # print(j)\n",
    "                split_col = [feature[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list.append(anderson_ksamp(split_col).significance_level)\n",
    "            count_dict[str(order)] += np.sum(np.asarray(p_list) < 0.05)\n",
    "    if len(batch_list) != 1:\n",
    "        best_order = [key for key, value in count_dict.items() if value == min(count_dict.values())][0]\n",
    "        best_order_list = list(map(int, best_order[1:-1].split(', ')))\n",
    "        order = [batch_list[i] for i in best_order_list]\n",
    "        n_dat = feature_dict[best_order]\n",
    "        final_estimate = estimate_dict[best_order] \n",
    "\n",
    "    print('Final Order: ' + str(order))\n",
    "\n",
    "    txt_path = filepath + 'order.txt'\n",
    "    with open(txt_path, 'w') as f:\n",
    "        for item in order:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    output_df = pd.DataFrame.from_records(n_dat.T)\n",
    "    output_df.columns = dat.index\n",
    "    if return_estimates:\n",
    "        return output_df, final_estimate\n",
    "    else:\n",
    "        return output_df\n",
    "\n",
    "\n",
    "def feature_ad(dat, output_df, covars, batch_list, filepath):\n",
    "    \"\"\"\n",
    "    Computes AD test p-values separated by batch effect groups for a dataset (intended to assess differences in\n",
    "    distribution to all batch effects in batch_list following harmonization NestedComBat\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (samples, features)\n",
    "    output_df: DataFrame of harmonized data with shape (samples, features)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "            encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : write destination for kernel density plots and p-values\n",
    "\n",
    "    If a feature is all the same value, the AD test cannot be completed.\n",
    "\n",
    "    \"\"\"\n",
    "    p_df_original = pd.DataFrame()\n",
    "    p_df_combat = pd.DataFrame()\n",
    "    for batch_col in batch_list:\n",
    "\n",
    "        # Computing KS Test P-Values\n",
    "        p_list_original = []\n",
    "        p_list_combat = []\n",
    "        for j in range(len(output_df.columns)):\n",
    "            feature_original = dat.iloc[:, j]\n",
    "            feature_combat = output_df.iloc[:, j]\n",
    "            try:\n",
    "                split_col_original = [feature_original[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list_original.append(anderson_ksamp(split_col_original).significance_level)\n",
    "                split_col_combat = [feature_combat[covars[batch_col] == i] for i in covars[batch_col].unique()]\n",
    "                p_list_combat.append(anderson_ksamp(split_col_combat).significance_level)\n",
    "            except ValueError:\n",
    "                print('Feature is all same value: ' + output_df.columns[j])\n",
    "\n",
    "        p_df_original[batch_col] = p_list_original\n",
    "        p_df_combat[batch_col] = p_list_combat\n",
    "\n",
    "    p_df_original.index = dat.columns\n",
    "    p_df_combat.index = output_df.columns\n",
    "    p_df_original.to_csv(filepath + 'p_values_original.csv')\n",
    "    p_df_combat.to_csv(filepath + 'p_values_combat.csv')\n",
    "    \n",
    "\n",
    "def feature_histograms(dat, output_df, covars, batch_list, filepath):\n",
    "    \"\"\"\n",
    "    Plots kernel density plots and computes KS test p-values separated by batch effect groups for a dataset (intended\n",
    "    to assess differences in distribution to all batch effects in batch_list following harmonization with\n",
    "    NestedComBat\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (samples, features)\n",
    "    output_df: DataFrame of harmonized data with shape (samples, features)\n",
    "    covars : DataFrame with shape (samples, covariates) corresponding to original data. All variables should be label-\n",
    "        encoded (i.e. strings converted to integer designations)\n",
    "    batch_list : list of strings indicating batch effect column names within covars (i.e. ['Manufacturer', 'CE'...])\n",
    "    filepath : write destination for kernel density plots and p-values\n",
    "    ad : KS test for binary batch effects if False, Anderson-Darling test for categorical batch effects if True\n",
    "\n",
    "    \"\"\"\n",
    "    for batch_col in batch_list:\n",
    "        filepath3 = filepath + batch_col + '/'\n",
    "        if not os.path.exists(filepath3):\n",
    "            os.makedirs(filepath3)\n",
    "\n",
    "        # Plotting Kernel Density Plots\n",
    "        for col in output_df:\n",
    "            feature_original = dat[col]\n",
    "            feature_combat = output_df[col]\n",
    "\n",
    "            try:\n",
    "\n",
    "                plt.figure()\n",
    "                for i in covars[batch_col].unique():\n",
    "                    feature_original[covars[batch_col] == i].plot.kde(color='r', alpha=0.75)\n",
    "                for i in covars[batch_col].unique():\n",
    "                    feature_combat[covars[batch_col] == i].plot.kde(color='b', alpha=0.5)\n",
    "                    if max(feature_combat[covars[batch_col] == i]) > 1:\n",
    "                        plt.xlim([0, 200])\n",
    "                plt.xlabel(col)\n",
    "                plt.ylabel('Density')\n",
    "                leg = ['Original', 'ComBat']\n",
    "                plt.legend(leg)\n",
    "                ax = plt.gca()\n",
    "                leg = ax.get_legend()\n",
    "                leg.legendHandles[0].set_color('r')\n",
    "                leg.legendHandles[1].set_color('b')\n",
    "\n",
    "                filename = filepath3 + 'histogram_' + col + \".png\"\n",
    "                plt.savefig(filename, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                plt.close('all')\n",
    "            except np.linalg.linalg.LinAlgError:\n",
    "                print('Failed to plot: ' + col)\n",
    "\n",
    "\n",
    "def GMMSplit(dat, caseno, filepath):\n",
    "    \"\"\"\n",
    "    Completes Gaussian Mixture model fitting and ComBat harmonization by the resulting sample grouping. The assumption\n",
    "    here is that there is an unknown batch effect causing bimodality such that we can estimate the sample groupings for\n",
    "    this hidden batch effect from the distribution. This function will take in a dataset, determine the best 2-component\n",
    "    Gaussian mixture model, and use the resulting sample grouping to harmonize the data with ComBat.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dat : DataFrame of original data with shape (features, samples)\n",
    "    caseno : DataFrame/Series containing sample IDs (should be aligned with dat and covars), used to return sample\n",
    "        grouping assignments.\n",
    "    filepath : root directory path for saving the grouping and corresponding kernel density plots\n",
    "    -------\n",
    "    new_dat : DataFrame with shape (features, samples) that has been sequentially harmonized with Nested ComBat\n",
    "\n",
    "    \"\"\"\n",
    "    # GENERATING GMM GROUPING\n",
    "    data_keys = list(dat.T.keys())\n",
    "    aic_values = []\n",
    "    predictions = []\n",
    "    col_list = []\n",
    "    final_keys = []\n",
    "    filepath2 = filepath+'GMM_Split/'\n",
    "    if not os.path.exists(filepath2):\n",
    "        os.makedirs(filepath2)\n",
    "\n",
    "    for i in range(len(data_keys)):\n",
    "        # print(col)\n",
    "        feature = dat.T.iloc[:, i]\n",
    "        X = pd.DataFrame({0: feature, 1: feature})\n",
    "        gmix = GaussianMixture(n_components=2)\n",
    "        col = data_keys[i]\n",
    "        try:\n",
    "            gmix.fit(X)\n",
    "            results = gmix.predict(X)\n",
    "            cluster_0 = X[results == 0].iloc[:, 0]\n",
    "            cluster_1 = X[results == 1].iloc[:, 0]\n",
    "            # print(len(cluster_0))\n",
    "            if len(cluster_0) <= .25*len(caseno) or len(cluster_1) <= .25*len(caseno):\n",
    "                print('Clusters unbalanced: ' + data_keys[i])\n",
    "            else:\n",
    "                try:\n",
    "                    plt.figure()\n",
    "                    cluster_0.plot.kde()\n",
    "                    cluster_1.plot.kde()\n",
    "                    X.iloc[:, 0].plot.kde()\n",
    "                    plt.legend(['Cluster 0', 'Cluster 1', 'Original'])\n",
    "                    plt.xlabel(data_keys[i])\n",
    "                    filename = filepath2 + 'histogram_' + data_keys[i] + \".png\"\n",
    "                    plt.savefig(filename, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                except:\n",
    "                    plt.close()\n",
    "                    print('Failed to plot: ' + col)\n",
    "                final_keys.append(col)\n",
    "                predictions.append(results)\n",
    "                aic_values.append(gmix.aic(X))\n",
    "                col_list.append(col)\n",
    "        except ValueError:\n",
    "            print('Failed to fit: ' + col)\n",
    "            # aic_values.append(np.nan)\n",
    "\n",
    "    # Returning AIC values\n",
    "    gaussian_df = pd.DataFrame({'Feature': final_keys, 'AIC': aic_values})\n",
    "    best_fit = gaussian_df[gaussian_df['AIC'] == min(gaussian_df['AIC'])]['Feature'].iloc[0].strip(' ')\n",
    "    best_fit_n = gaussian_df[gaussian_df['AIC'] == min(gaussian_df['AIC'])]['Feature'].index[0]\n",
    "    gaussian_df.to_csv(filepath2 + 'GaussianMixture_aic_values.csv')\n",
    "\n",
    "    # Returning patient split\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df['Patient'] = caseno\n",
    "    predictions_df['Grouping'] = predictions[best_fit_n]\n",
    "    predictions_df.to_csv(filepath2 + best_fit + '_split.csv')\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fed9ca-afd8-4478-93f7-f38de22faa19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading in features\n",
    "filepath = \"Testing/ComBat/\"\n",
    "filepath2 = 'Testing/ComBat/ResultTesting'\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(filepath)\n",
    "if not os.path.exists(filepath2):\n",
    "    os.makedirs(filepath2)\n",
    "\n",
    "# Loading in batch effects\n",
    "\n",
    "batch_testing_df = pd.read_csv('C:/Projects/brainspin/not_pushed/data_anonymized/combos/CombinedDataset_Batch.csv')\n",
    "batch_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bdb46-11cd-425e-81c7-3ca0f56340bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading in batch effects\n",
    "batch_testing_list = ['Site']\n",
    "# Loading in clinical covariates\n",
    "categorical_testing_cols = ['Sex']\n",
    "continuous_testing_cols = ['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4f817d-1f6b-4c0b-abce-588ee950d8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ASL\n",
    "data_testing_df = pd.read_csv('C:/Projects/brainspin/not_pushed/data_anonymized/combos/CombinedDataset.csv')\n",
    "data_testing_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3651-f41a-4107-9f59-54c509bb87e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_testing_df = data_testing_df.reset_index(drop=True)\n",
    "data_testing_df = data_testing_df.dropna()\n",
    "data_testing_df = data_testing_df.merge(batch_testing_df['SUBJECT'], left_on='SUBJECT', right_on='SUBJECT')\n",
    "dat_testing = data_testing_df.iloc[:, 1:]\n",
    "dat_testing = dat_testing.T.apply(pd.to_numeric)\n",
    "caseno_testing = data_testing_df['SUBJECT']\n",
    "covars_testing = batch_testing_df.drop('SUBJECT',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdf91f-565d-4dbd-8a6a-e40ccdca757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea5694-475f-4187-96ce-01ded9893236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging batch effects, clinical covariates\n",
    "covars_testing_string = pd.DataFrame()\n",
    "covars_testing_string[categorical_testing_cols] = covars_testing[categorical_testing_cols].copy()\n",
    "covars_testing_quant = covars_testing[continuous_testing_cols]\n",
    "\n",
    "# Encoding categorical variables\n",
    "covars_testing_cat = pd.DataFrame()\n",
    "for col_testing in covars_testing_string:\n",
    "    stringcol_testing = covars_testing_string[col_testing]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(stringcol_testing))\n",
    "    covars_testing_cat[col_testing] = le.transform(stringcol_testing)\n",
    "\n",
    "covars_testing_final = pd.concat([covars_testing_cat, covars_testing_quant], axis=1)\n",
    "\n",
    "# # FOR GMM COMBAT VARIANTS:\n",
    "# # Adding GMM Split to batch effects\n",
    "gmm_testing_df = GMMSplit(dat_testing, caseno_testing, filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e0a92-fb87-46c2-9d7a-74f09b4bebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f3f05-bc83-47cb-86f9-d9d66eddd08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gmm_testing_df_merge = batch_testing_df.merge(gmm_testing_df, right_on='Patient', left_on='SUBJECT')\n",
    "gmm_testing_df_merge['GMM'] = gmm_testing_df_merge['Grouping'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e9c5d-7eb9-4760-8f61-c1a391b88bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_testing_df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f137865-373a-49e7-a735-81b2e02fc370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covars_testing_final = gmm_testing_df_merge.drop(['SUBJECT','Patient','Grouping'],1)\n",
    "categorical_testing_cols = categorical_testing_cols + ['GMM']\n",
    "\n",
    "# Completing Nested ComBat\n",
    "output_testing_df = OPNestedComBat(dat_testing, covars_testing_final, batch_testing_list, filepath2, categorical_cols=categorical_testing_cols,\n",
    "                                  continuous_cols=continuous_testing_cols)\n",
    "write_testing_df = pd.concat([caseno_testing, output_testing_df], axis=1) \n",
    "write_testing_df.to_csv(filepath2+'/features_testing_NestedComBat.csv') # write results fo file\n",
    "dat_testing_input = dat_testing.transpose()\n",
    "dat_testing_input.to_csv(filepath2+'/features_input_testing_NestedComBat.csv')\n",
    "covars_testing_final.to_csv(filepath2+'/covars_input_testing_NestedComBat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3e754-41f2-4ba1-aa41-fc5c98180ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the AD test p-values to measure harmonziation performance\n",
    "feature_ad(dat_testing.T, output_testing_df, covars_testing_final, batch_testing_list, filepath2)\n",
    "# Plot kernel density plots to visualize distributions before and after harmonization\n",
    "feature_histograms(dat_testing.T, output_testing_df, covars_testing_final, batch_testing_list, filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2ce55-bd52-4c76-ae54-83aceda7d41c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% visualisation\n",
    "# library & dataset\n",
    "\n",
    "complete_harmonised = pd.concat([write_testing_df, covars_testing_final], axis=1) \n",
    "complete_harmonised['Harmonised'] = 'H'\n",
    "complete_nonharmonised = pd.concat([caseno_testing, dat_testing_input], axis=1) \n",
    "complete_nonharmonised = pd.concat([complete_nonharmonised, covars_testing_final], axis=1) \n",
    "complete_nonharmonised['Harmonised'] = 'UH'\n",
    "complete_harmonised_nonharmonised_merged = complete_harmonised.append(complete_nonharmonised)\n",
    "\n",
    "complete_harmonised_nonharmonised_merged = complete_harmonised_nonharmonised_merged\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.nan\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['Sex'] == 0) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'H'), 'H_Male', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['Sex'] == 1) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'H'), 'H_Female', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['Sex'] == 0) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'UH'), 'UH_Male', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonised_sex'] = np.where((complete_harmonised_nonharmonised_merged['Sex'] == 1) & (complete_harmonised_nonharmonised_merged['Harmonised'] == 'UH'), 'UH_Female', complete_harmonised_nonharmonised_merged['Harmonised_sex'])\n",
    "complete_harmonised_nonharmonised_merged['Harmonisation'] = complete_harmonised_nonharmonised_merged['Harmonised']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.catplot(data = complete_harmonised_nonharmonised_merged, x = 'Harmonisation', y = \"TotalGM_B_CBF\", hue =\"Sex\", \n",
    "split=True, inner = 'quartile', kind = 'violin', \n",
    "col = 'Site', height = 5, aspect = 0.6)\n",
    "plt.ylim((-20,150))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa631b-d7a2-4256-a1f1-42c11443a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_harmonised_nonharmonised_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051ea31-1466-4770-a8dc-6737f7a74614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
