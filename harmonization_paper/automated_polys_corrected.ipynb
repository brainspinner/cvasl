{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generalized polynomial based work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook covers comparing two datasets, one of which will be considered the \"base\" dataset, and one will be the dataset which we compare to.\n",
    "The environment is the normal cvasl environment (mrilander)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os       # using operating system dependent functionality (folders)\n",
    "import glob\n",
    "import pandas as pd # data analysis and manipulation\n",
    "import numpy as np    # numerical computing (manipulating and performing operations on arrays of data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../') # path to our library functions\n",
    "from cvasl import file_handler as fh # \n",
    "from cvasl import mold #\n",
    "from cvasl import carve\n",
    "from cvasl import seperated\n",
    "from cvasl.file_handler import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up data pull\n",
    "config = Config.from_file()\n",
    "root_mri_directory = config.get_directory('raw_data')\n",
    "root_mri_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Setting the base and comapared datasets\n",
    "In this example we will use the TOP dataset as our base, and mriStroke as the other dataset.\n",
    "This is highly problematic for anything stratified by gender, but we will overlook that for now,\n",
    "as both datasets have about 50% women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base = os.path.join(root_mri_directory, 'assembled/top_stitched.csv')\n",
    "compared = os.path.join(root_mri_directory, 'assembled/StrokeMRI_stitched.csv')\n",
    "# in the future the below should be base_data and the tricks will skip\n",
    "our_top_data = pd.read_csv(base)\n",
    "dataframe_compared = pd.read_csv(compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We may have a mistake in our_top_data, white matter hyperintensities...also the total flows have outlier max values. Let's look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### temporary trick to deal with data inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data['GM_vol'] = our_top_data['GM_vol_Liter']\n",
    "our_top_data['WM_vol'] = our_top_data['WM_vol_Liter']\n",
    "our_top_data['CSF_vol'] = our_top_data['CSF_vol_Liter']\n",
    "our_top_data['GM_ICVRatio'] = our_top_data['GM_ICVRatio_ratio GM/ICV'] \n",
    "our_top_data['WMH_vol'] = our_top_data['GMWM_ICVRatio_ratio (GM+WM)/ICV']\n",
    "our_top_data['WMH_count'] = our_top_data['WMH_count_n lesions (integer)']\n",
    "our_top_data['DeepWM_B'] = our_top_data['DeepWM_B_SD/mean']\n",
    "our_top_data['DeepWM_L'] = our_top_data['DeepWM_L_SD/mean']\n",
    "our_top_data['DeepWM_L'] = our_top_data['DeepWM_R_SD/mean']\n",
    "our_top_data['ACA_B']= our_top_data['ACA_B_SD/mean']    \n",
    "our_top_data['ACA_L']= our_top_data['ACA_L_SD/mean']           \n",
    "our_top_data['ACA_R']= our_top_data['ACA_R_SD/mean']            \n",
    "our_top_data['MCA_B']= our_top_data['MCA_B_SD/mean']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(our_top_data['Age'],our_top_data['WMH_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data[our_top_data['WMH_count'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data[our_top_data['WMH_count'] > 100]['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Needs scientist decision\n",
    "Someone with 570 WMH at age of 41 is abnormal, is there a mistake in the data? Also note the volumes are not particularly large.Or a sick patient?\n",
    "Should we  drop such outliers? Automatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(dataframe_compared['Age'],dataframe_compared['WMH_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Moving on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we find common columns; this will be easier when all is same formatted\n",
    "shared_columns = (\n",
    "        dataframe_compared.columns.intersection(our_top_data.columns)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### create base polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find common columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "special_data_column = 'Age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_columns = [\n",
    "    'GM_vol',\n",
    "     'WM_vol',\n",
    "     'CSF_vol',\n",
    "     'GM_ICVRatio',\n",
    "     'WMH_vol',\n",
    "     'WMH_count',\n",
    "     'DeepWM_B',\n",
    "     'DeepWM_L',\n",
    "     'ACA_B',\n",
    "     'ACA_L',\n",
    "     'ACA_R',\n",
    "     'MCA_B', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# below functions must go into main library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def polyfit_second_degree_to_df(\n",
    "        dataframe,\n",
    "        special_column_name,\n",
    "        other_column_names,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates a polynomial for two columns.\n",
    "    It returns the coefficients\n",
    "    \n",
    "    :param dataframe: dataframe variable\n",
    "    :type dataframe: pandas.dataFrame\n",
    "    :param special_column_name: string of column you want to graph against\n",
    "    :type  special_column_name: str\n",
    "    :param other_column_name: string of column you want to graph\n",
    "    :type other_column_name: str\n",
    "    :param degree_poly: either 1,2 or 3 only\n",
    "    :type  degree_poly: int\n",
    "\n",
    "\n",
    "    :returns: coeffiects\n",
    "    :rtype: :class:`~numpy.ndarray`\n",
    "    \"\"\"\n",
    "    list_as = []\n",
    "    list_bs = []\n",
    "    list_cs = []\n",
    "    list_columns = []\n",
    "    dataframe = dataframe.dropna()\n",
    "    for interest_column_name in other_column_names:\n",
    "        xscat = np.array(pd.to_numeric(dataframe[special_column_name]))\n",
    "        yscat = np.array(pd.to_numeric(dataframe[interest_column_name]))\n",
    "        coefficients = np.polyfit(xscat, yscat, 2 ) #2 = degree_poly\n",
    "        list_columns.append(interest_column_name)\n",
    "        list_as.append(coefficients[0])\n",
    "        list_bs.append(coefficients[1])\n",
    "        list_cs.append(coefficients[2])\n",
    "    d = {'column':list_columns,'coefficient_a':list_as, 'coefficient_b':list_bs, 'coefficient_c':list_cs}\n",
    "    coefficien_dataframe = pd.DataFrame(d)\n",
    "   \n",
    "    return coefficien_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def derived_function(column, a, b, c):\n",
    "    return a * (column**2) + b * column + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_dataframe = polyfit_second_degree_to_df(\n",
    "        our_top_data,#dataframe_base,\n",
    "        special_data_column,\n",
    "        other_columns,\n",
    ")\n",
    "cos_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "projected_columns = []\n",
    "coefficients = ['coefficient_a', 'coefficient_b', 'coefficient_c']\n",
    "for column in our_top_data[shared_columns].columns:\n",
    "    projected_columns.append(column + '_projected')\n",
    "    row = cos_dataframe[cos_dataframe['column'] == column]\n",
    "    if row.empty:\n",
    "        # The columns that appear \"weird\" below (eg. `Series([], dtype: float64)`)\n",
    "        # are the columns not found in `cos_dataframe`, so they don't have associated coefficients..\n",
    "        print('skipping', column)\n",
    "        continue\n",
    "    a, b, c = row[coefficients].values.flatten().tolist()\n",
    "    our_top_data[column + '_projected'] = derived_function(our_top_data['Age'], a, b, c)\n",
    "our_top_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_columns_new =  ['GM_vol',\n",
    " 'WM_vol',\n",
    " 'CSF_vol',\n",
    " 'GM_ICVRatio',\n",
    " 'WMH_vol',\n",
    " 'WMH_count',\n",
    " 'DeepWM_B',\n",
    " 'DeepWM_L',\n",
    " 'ACA_B',\n",
    " 'ACA_L',\n",
    " 'ACA_R',\n",
    " 'MCA_B',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "difference_columns = []\n",
    "for column in our_top_data[shared_columns_new].columns:\n",
    "    difference_columns.append(column+ '_diff')\n",
    "    our_top_data[column + '_diff'] = our_top_data[column] - our_top_data[column + '_projected']\n",
    "    our_top_data[column + '_abs_diff'] = abs(our_top_data[column] - our_top_data[column + '_projected'])\n",
    "our_top_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Now we want to do the same to the compared dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataframe_compared\n",
    "\n",
    "projected_columns = []\n",
    "coefficients = ['coefficient_a', 'coefficient_b', 'coefficient_c']\n",
    "for column in dataframe_compared[shared_columns].columns:\n",
    "    projected_columns.append(column + '_projected')\n",
    "    row = cos_dataframe[cos_dataframe['column'] == column]\n",
    "    if row.empty:\n",
    "        # The columns that appear \"weird\" below (eg. `Series([], dtype: float64)`)\n",
    "        # are the columns not found in `cos_dataframe`, so they don't have associated coefficients..\n",
    "        print('skipping', column)\n",
    "        continue\n",
    "    a, b, c = row[coefficients].values.flatten().tolist()\n",
    "    dataframe_compared[column + '_projected'] = derived_function(dataframe_compared['Age'], a, b, c)\n",
    "difference_columns = []\n",
    "for column in dataframe_compared[shared_columns_new].columns:\n",
    "    difference_columns.append(column+ '_diff')\n",
    "    dataframe_compared[column + '_diff'] = dataframe_compared[column] - dataframe_compared[column + '_projected']\n",
    "    dataframe_compared[column + '_abs_diff'] = abs(dataframe_compared[column] - dataframe_compared[column + '_projected'])\n",
    "dataframe_compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shared_columns_rel = ['GM_vol',\n",
    " 'WM_vol',\n",
    " 'CSF_vol',\n",
    " 'GM_ICVRatio',\n",
    " 'WMH_vol',\n",
    " 'WMH_count',\n",
    " 'DeepWM_B',\n",
    " 'DeepWM_L',\n",
    " 'ACA_B',\n",
    " 'ACA_L',\n",
    " 'ACA_R',\n",
    " 'MCA_B',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in our_top_data[shared_columns_rel].columns:\n",
    "    plt.figure()\n",
    "    plt.title('base_dataframe ' +column)\n",
    "    plt.scatter(our_top_data['Age'],our_top_data[column])\n",
    "    plt.scatter(our_top_data['Age'],our_top_data[column + '_projected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataframe_compared[shared_columns_rel].columns:\n",
    "    plt.figure()\n",
    "    plt.title('compared ' +column)\n",
    "    plt.scatter(dataframe_compared['Age'],dataframe_compared[column], color='purple')\n",
    "    plt.scatter(dataframe_compared['Age'],dataframe_compared[column + '_projected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## describe the differences in base dataframe, the compared dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_diff_dc =dataframe_compared.columns[dataframe_compared.columns.str.contains(\"diff\")].to_list()\n",
    "list_diff_top = our_top_data.columns[our_top_data.columns.str.contains(\"diff\")].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data[list_diff_top].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_compared[list_diff_dc].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe_compared[list_diff_dc].describe().loc['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data[list_diff_dc].describe().loc['max'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if this number is positive or zero we are golden!\n",
    "outer_top_minus_outer_mri_top_poly = our_top_data[list_diff_dc].describe().loc['max'] - dataframe_compared[list_diff_dc].describe().loc['max'] \n",
    "outer_top_minus_outer_mri_top_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# needs recode\n",
    "(len(outer_top_minus_outer_mri_top_poly) - len(outer_top_minus_outer_mri_top_poly[outer_top_minus_outer_mri_top_poly > 0])) / len(outer_top_minus_outer_mri_top_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "So about a third of the values get into a range outside the expected...but by how much?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "We need to look into (should be compared as a percentage of average values?):\n",
    "\n",
    "\n",
    "\n",
    "WM_vol_abs_diff          -0.001561\n",
    "\n",
    "\n",
    "CSF_vol_abs_diff         -0.031943\n",
    "\n",
    "\n",
    "GM_ICVRatio_abs_diff     -0.021200\n",
    "\n",
    "\n",
    "WMH_vol_abs_diff        -64.356226"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardd coding to be replaces\n",
    "WM_vol_abs_diff = -0.001561\n",
    "WM_vol_abs_diff /our_top_data['WM_vol'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CSF_vol_abs_diff =  -0.031943\n",
    "CSF_vol_abs_diff  / our_top_data['CSF_vol'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "tags": []
   },
   "source": [
    "so we do see a 10% difference in csf volumne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GM_ICVRatio_abs_diff = -0.021200\n",
    "GM_ICVRatio_abs_diff /our_top_data['GM_ICVRatio'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "and a 4% difference in GMICV radio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WMH_vol_abs_diff  = -64.356226\n",
    "WMH_vol_abs_diff/ our_top_data['WMH_vol'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "but a huge difference in white matter pter intensity. As the true nature of the curve is shown only in the later ages?\n",
    "But maybe step 2 is to apply a transformation matrix to the outliers,.\n",
    "\n",
    "\n",
    "Then we are talking about an algorithm that identifies the outliers, and pushes them through a transformation matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {
    "tags": []
   },
   "source": [
    "Anyways, first some histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data[list_diff_top].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "our_top_data['WMH_count_diff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each feature make a histogram for  difference\n",
    "for column_d in our_top_data[list_diff_top].columns:\n",
    "    if 'abs' not in column_d: # add if to get rid of abs\n",
    "        plt.figure()\n",
    "        plt.title(column_d + ' base distribution')\n",
    "        plt.text(x=0.07, y= 60, s=\"Skewness: %f\" % our_top_data[column_d].skew(),\\\n",
    "        fontweight='demibold', fontsize=8,\n",
    "        backgroundcolor='white', color='xkcd:poo brown')\n",
    "        plt.text(x=0.07, y= 55, s=\"Kurtosis: %f\" % our_top_data[column_d].kurt(),\\\n",
    "        fontweight='demibold', fontsize=8, \n",
    "        backgroundcolor='white', color='xkcd:dried blood')\n",
    "        our_top_data[column_d].hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each feature make a histogram for  difference\n",
    "for column_d in dataframe_compared[list_diff_top].columns:\n",
    "    if 'abs' not in column_d: # add if to get rid of abs\n",
    "        plt.figure()\n",
    "        plt.title(column_d + ' compared distribution')\n",
    "        plt.text(x=0.07, y= 65, s=\"Skewness: %f\" % dataframe_compared[column_d].skew(),\\\n",
    "        fontweight='demibold', fontsize=8,\n",
    "        backgroundcolor='white', color='xkcd:poo brown')\n",
    "        plt.text(x=0.07, y= 55, s=\"Kurtosis: %f\" % dataframe_compared[column_d].kurt(),\\\n",
    "        fontweight='demibold', fontsize=8, \n",
    "        backgroundcolor='white', color='xkcd:dried blood')\n",
    "        dataframe_compared[column_d].hist(color='purple')\n",
    "        #print(type(dataframe_compared[column_d].hist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get ready to rescale values on histograms to match\n",
    "multiplier = len(our_top_data)/len(dataframe_compared)\n",
    "multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each feature make a histogram for  difference on both datasets\n",
    "for column_d in our_top_data[list_diff_top].columns:\n",
    "    if our_top_data[column_d].max() > dataframe_compared[column_d].max():\n",
    "        find_true_max = our_top_data[column_d].max()\n",
    "    else:\n",
    "        find_true_max = dataframe_compared[column_d].max()\n",
    "        \n",
    "    if 'abs' not in column_d: # add if to get rid of abs\n",
    "\n",
    "        base_df_histogram , bin_edges= np.histogram(our_top_data[column_d], bins=10, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        comapred_df_histogram , bin_edges = np.histogram(dataframe_compared[column_d], bins=10, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        scaled_comparison_histogram = comapred_df_histogram * multiplier\n",
    "        plt.figure(figsize=[10,6])\n",
    "\n",
    "        plt.bar(bin_edges[:10], base_df_histogram, width = 0.03, color='#0504aa',alpha=0.5)\n",
    "        plt.xlim(min(bin_edges), max(bin_edges))\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylabel('Frequency',fontsize=15)\n",
    "        #plt.title('Difference from Polynomial Distribution Histograms',fontsize=15)\n",
    "        #plt.show()\n",
    "        plt.bar(bin_edges[:10], scaled_comparison_histogram, width = 0.03, color='#FF00FF',alpha=0.5)\n",
    "        plt.xlim(min(bin_edges), max(bin_edges))\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.xlabel('Residuals Scaled',fontsize=15)\n",
    "        plt.ylabel('Frequency',fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylabel('Frequency',fontsize=15)\n",
    "        plt.title('Difference from Polynomial Distribution Histogram ' + column_d,fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now we need to describe the residual differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "# So we want our histogram to be comparable to other histograms...we can scale every histogram to a 100 patient population,not so coincidentally, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for each feature make a histogram of residual diferenes for difference on both datasets\n",
    "for column_d in our_top_data[list_diff_top].columns:\n",
    "    if our_top_data[column_d].max() > dataframe_compared[column_d].max():\n",
    "        find_true_max = our_top_data[column_d].max()\n",
    "    else:\n",
    "        find_true_max = dataframe_compared[column_d].max()     \n",
    "    if 'abs' not in column_d: # add if to get rid of abs\n",
    "        base_df_histogram , bin_edges= np.histogram(our_top_data[column_d], bins=10, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        comapred_df_histogram , bin_edges = np.histogram(dataframe_compared[column_d], bins=10, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        scaled_comparison_histogram = comapred_df_histogram * multiplier\n",
    "        scaled_histogram_difference = base_df_histogram - scaled_comparison_histogram\n",
    "        hundred_scaled_histo_diff = scaled_histogram_difference * (100 / len(our_top_data))\n",
    "        plt.figure(figsize=[10,6])\n",
    "\n",
    "        plt.bar(bin_edges[:10], hundred_scaled_histo_diff, width = 0.03, color='#0504aa',alpha=0.5)\n",
    "        plt.xlim(min(bin_edges), max(bin_edges))\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.xlabel('Value Difference between two distributions for ' + column_d,fontsize=15)\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylabel('Frequency',fontsize=15)\n",
    "        plt.title('\"Residuals\" differences',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Now we  will calculate a \"rough integral difference for each feature\"\n",
    "by summing these differences...and we will also add information on kurtosis and skew for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "rough_integral_diff = []\n",
    "scew_base = []\n",
    "scew_compared = []\n",
    "kurtosis_base = []\n",
    "kurtosis_compared = []\n",
    "\n",
    "for column_d in our_top_data[list_diff_top].columns:\n",
    "    if our_top_data[column_d].max() > dataframe_compared[column_d].max():\n",
    "        find_true_max = our_top_data[column_d].max()\n",
    "    else:\n",
    "        find_true_max = dataframe_compared[column_d].max()     \n",
    "    if 'abs' not in column_d: # add if to get rid of abs\n",
    "        base_df_histogram , bin_edges= np.histogram(our_top_data[column_d], bins=20, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        comapred_df_histogram , bin_edges = np.histogram(dataframe_compared[column_d], bins=20, range=(-find_true_max , find_true_max ), density=None, weights=None)\n",
    "        scaled_comparison_histogram = comapred_df_histogram * multiplier\n",
    "        scaled_histogram_difference = base_df_histogram - scaled_comparison_histogram\n",
    "        hundred_scaled_histo_diff = scaled_histogram_difference * (100 / len(our_top_data))\n",
    "        scew_base_i = our_top_data[column_d].skew()\n",
    "        scew_compared_i = dataframe_compared[column_d].skew()\n",
    "        kurt_base_i = our_top_data[column_d].kurt()\n",
    "        kurt_compared_i = dataframe_compared[column_d].kurt()\n",
    "    scew_base.append(scew_base_i )\n",
    "    scew_compared.append(scew_compared_i )\n",
    "    kurtosis_base.append(kurt_base_i )\n",
    "    kurtosis_compared.append(kurt_compared_i )\n",
    "    features.append(column_d)\n",
    "    rough_integral_diff.append(hundred_scaled_histo_diff.sum())\n",
    "    integ_dataframe = {\n",
    "        'feature':features,\n",
    "        'integral diff':rough_integral_diff,\n",
    "        'skew_base': scew_base,\n",
    "        'skew_compared': scew_compared,\n",
    "        'kurtosis_base': kurtosis_base,\n",
    "        'kurtosis_compared': kurtosis_compared,\n",
    "    }\n",
    "hop = pd.DataFrame(integ_dataframe)\n",
    "hop   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "So we see that once we scale the datasets as if they were 100 people, the maximal to fall on a different distance from the polynimial and underlying base distribution is about 11. Our white matter hyperintensity count is a bit strange, but this needs data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_polynomial1 = seperated.polyfit_and_show(\n",
    "        our_top_data,\n",
    "        'Age',\n",
    "        'WMH_count',\n",
    "        2,\n",
    "        color1='purple',\n",
    ")\n",
    "mri_polynomial2 = seperated.polyfit_and_show(\n",
    "        dataframe_compared,\n",
    "        'Age',\n",
    "        'WMH_count',\n",
    "        2,\n",
    "        color1='orange',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_top_data = our_top_data[our_top_data['WMH_count'] < 80]\n",
    "filtered_mri_data = dataframe_compared[dataframe_compared['WMH_count'] < 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_polynomial1 = seperated.polyfit_and_show(\n",
    "        filtered_top_data,\n",
    "        'Age',\n",
    "        'WMH_count',\n",
    "        2,\n",
    "        color1='purple',\n",
    ")\n",
    "mri_polynomial2 = seperated.polyfit_and_show(\n",
    "        filtered_mri_data,\n",
    "        'Age',\n",
    "        'WMH_count',\n",
    "        2,\n",
    "        color1='orange',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Above shows that filtering down to a potentially clinically reasonable number if white matter hypterintensities brings polynomials closer...but what is clinically reasonable?\n",
    "# To be discussed with scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
